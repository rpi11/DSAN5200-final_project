[
  {
    "objectID": "viz_Zenan/viz.html",
    "href": "viz_Zenan/viz.html",
    "title": "Viz 5",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport warnings\nwarnings.filterwarnings('ignore')\nwith open(\"../data/data.csv\", \"r\") as f:\n    df = pd.read_csv(f)\ndf.head()\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n0\nCounty\nAirports\nTotal Airports\nGrant County, Wisconsin\n01/01/2020 12:00:00 AM\n55043\n55\nWisconsin\n9.0\n9.0\nTotal Airports\nairports-2020-55043\n42.867479\n-90.706205\nPOINT (-90.706205 42.867479)\n2020\n\n\n1\nCounty\nAirports\nTotal Airports\nTaylor County, Florida\n01/01/2020 12:00:00 AM\n12123\n12\nFlorida\n7.0\n7.0\nTotal Airports\nairports-2020-12123\n30.047015\n-83.603520\nPOINT (-83.60352 30.047015)\n2020\n\n\n2\nCounty\nAirports\nTotal Airports\nStephens County, Texas\n01/01/2020 12:00:00 AM\n48429\n48\nTexas\n2.0\n2.0\nTotal Airports\nairports-2020-48429\n32.735872\n-98.836184\nPOINT (-98.836184 32.735872)\n2020\n\n\n3\nCounty\nAirports\nOther airports\nKnox County, Maine\n01/01/2020 12:00:00 AM\n23013\n23\nMaine\n7.0\n9.0\nTotal Airports\nother-airports-2020-23013\n44.155975\n-69.234045\nPOINT (-69.234045 44.155975)\n2020\n\n\n4\nCounty\nAirports\nPrimary Airports\nColfax County, New Mexico\n01/01/2020 12:00:00 AM\n35007\n35\nNew Mexico\n0.0\n5.0\nTotal Airports\nprimary-airports-2020-35007\n36.606139\n-104.646840\nPOINT (-104.64684 36.606139)\n2020\nfiltered_df = df[(df['Category'] == 'Person trips') & (df['Variable'] == 'Total trips')]\nprint(filtered_df)\n\n         Level      Category     Variable                        County  \\\n338538  County  Person trips  Total trips        Adair County, Kentucky   \n338541  County  Person trips  Total trips        Cass County, Minnesota   \n338543  County  Person trips  Total trips        Dundy County, Nebraska   \n338545  County  Person trips  Total trips          Menard County, Texas   \n338547  County  Person trips  Total trips        Malheur County, Oregon   \n...        ...           ...          ...                           ...   \n407541  County  Person trips  Total trips  Judith Basin County, Montana   \n407576  County  Person trips  Total trips       Massac County, Illinois   \n407577  County  Person trips  Total trips     Orange County, California   \n407589  County  Person trips  Total trips    Butte County, South Dakota   \n407596  County  Person trips  Total trips         Caribou County, Idaho   \n\n                          Date  GEOID  State FIPS         State         Value  \\\n338538  01/01/2019 12:00:00 AM  21001          21      Kentucky  2.690490e+07   \n338541  01/01/2020 12:00:00 AM  27021          27     Minnesota  3.458602e+07   \n338543  01/01/2019 12:00:00 AM  31057          31      Nebraska  2.444445e+06   \n338545  01/01/2020 12:00:00 AM  48327          48         Texas  2.741053e+06   \n338547  01/01/2019 12:00:00 AM  41045          41        Oregon  6.099970e+07   \n...                        ...    ...         ...           ...           ...   \n407541  01/01/2019 12:00:00 AM  30045          30       Montana  2.284353e+06   \n407576  01/01/2020 12:00:00 AM  17127          17      Illinois  2.246585e+07   \n407577  01/01/2020 12:00:00 AM   6059           6    California  3.002547e+09   \n407589  01/01/2019 12:00:00 AM  46019          46  South Dakota  1.430882e+07   \n407596  01/01/2020 12:00:00 AM  16029          16         Idaho  6.149330e+06   \n\n         Denominator Denominator Description            Row-ID   Latitude  \\\n338538  2.690490e+07            Person trips  trips-2019-21001  37.104170   \n338541  3.458602e+07            Person trips  trips-2020-27021  47.117876   \n338543  2.444445e+06            Person trips  trips-2019-31057  40.176201   \n338545  2.741053e+06            Person trips  trips-2020-48327  30.889818   \n338547  6.099970e+07            Person trips  trips-2019-41045  43.193414   \n...              ...                     ...               ...        ...   \n407541  2.284353e+06            Person trips  trips-2019-30045  47.045432   \n407576  2.246585e+07            Person trips  trips-2020-17127  37.218970   \n407577  3.002547e+09            Person trips  trips-2020-06059  33.702972   \n407589  1.430882e+07            Person trips  trips-2019-46019  44.905772   \n407596  6.149330e+06            Person trips  trips-2020-16029  42.770497   \n\n         Longitude                       Location  Year  \n338538  -85.280620     POINT (-85.28062 37.10417)  2019  \n338541  -94.280528   POINT (-94.280528 47.117876)  2020  \n338543 -101.687947  POINT (-101.687947 40.176201)  2019  \n338545  -99.820600     POINT (-99.8206 30.889818)  2020  \n338547 -117.623150   POINT (-117.62315 43.193414)  2019  \n...            ...                            ...   ...  \n407541 -110.266027  POINT (-110.266027 47.045432)  2019  \n407576  -88.707722    POINT (-88.707722 37.21897)  2020  \n407577 -117.761070   POINT (-117.76107 33.702972)  2020  \n407589 -103.507928  POINT (-103.507928 44.905772)  2019  \n407596 -111.562260   POINT (-111.56226 42.770497)  2020  \n\n[6279 rows x 16 columns]\naggregated_df = df.groupby('State')['Value'].sum().reset_index()\ndef abbreviate_states(states):\n    state_dict = {\n        'Alabama': 'AL', 'Alaska': 'AK', 'American Samoa': 'AS', 'Arizona': 'AZ', 'Arkansas': 'AR',\n        'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL',\n        'Georgia': 'GA', 'Guam': 'GU', 'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL',\n        'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA',\n        'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN',\n        'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n        'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n        'North Dakota': 'ND', 'Northern Mariana Islands': 'MP', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR',\n        'Pennsylvania': 'PA', 'Puerto Rico': 'PR', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',\n        'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virgin Islands': 'VI',\n        'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY',\n        'District of Columbia': 'DC'\n    }\n    abbreviated_states = [state_dict[state] if state in state_dict else state for state in states]\n\n    return abbreviated_states\n\naggregated_df['State'] = abbreviate_states(aggregated_df['State'])\n\nfig = px.choropleth(\n    aggregated_df,\n    locations='State',\n    color_continuous_scale=\"Viridis\",\n    locationmode='USA-states',\n    color='Value',\n    scope='usa',\n    title='Choropleth Map based on State Values of Travel Frequency'\n)\n\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\nfiltered_df = filtered_df[filtered_df['State'].isin([\"California\", \"Texas\", \"New York\", \"Florida\", \"Illinois\"])]\nvalues=filtered_df['Value']\nendpts = list(np.mgrid[min(values):max(values):50j])\nfig = ff.create_choropleth(fips=filtered_df['GEOID'], values=values,  legend_title='Travel Frequency by County in the top 5 States with most Aggregated Trips')\nfig.layout.template = None\nfig.update_layout(\n    legend_x = 0,\n    annotations = {'x': -0.5, 'xanchor': 'left'}\n)\nfig.show()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json\ntop_100_values_df = filtered_df.nlargest(100, 'Value')\ndf_with_top100_travel = df[df['GEOID'].isin(top_100_values_df['GEOID'])]\ndf_with_top100_travel = df_with_top100_travel[df_with_top100_travel['Category'].isin(['Business', 'Commuting'])]\ndf_with_top100_travel = df_with_top100_travel[(df_with_top100_travel['Variable'] == 'Establishments') | (df_with_top100_travel['Variable'] == \"Commute by car/ truck/van\")]"
  },
  {
    "objectID": "viz_Zenan/viz.html#viz-5",
    "href": "viz_Zenan/viz.html#viz-5",
    "title": "Viz 5",
    "section": "Viz 5",
    "text": "Viz 5\n\npivoted_df = df_with_top100_travel.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\npivoted_df.plot(kind='bar', figsize=(10, 6))\n\nplt.xlabel('County name')\nplt.ylabel('Value')\nplt.title('Comparison of Commuting (Personal vehicle) vs. Business (Establishments) for the Counties with top 100 most Travel')\nplt.show()\n\n\n\n\n\n\n\n\n\ntop_100_values_df = filtered_df.nlargest(100, 'Value')\ndf_with_top100_travel = df[df['GEOID'].isin(top_100_values_df['GEOID'])]\ndf_with_top100_travel = df_with_top100_travel[df_with_top100_travel['Category'].isin(['Bridges', 'Commuting'])]\ndf_with_top100_travel = df_with_top100_travel[(df_with_top100_travel['Variable'] == \"Bridge area, good (square meters)\") | (df_with_top100_travel['Variable'] == \"Commute by car/ truck/van\")]"
  },
  {
    "objectID": "viz_Zenan/viz.html#viz-6",
    "href": "viz_Zenan/viz.html#viz-6",
    "title": "Viz 5",
    "section": "Viz 6",
    "text": "Viz 6\n\npivoted_df = df_with_top100_travel.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\npivoted_df.plot(kind='bar', figsize=(10, 6))\n\nplt.xlabel('County name')\nplt.ylabel('Value')\nplt.title('Comparison of Commuting (Personal vehicle) vs. Bridges(Bridge area, good (square meters)) for the Counties with top 100 most Travel')\nplt.show()\n\n\n\n\n\n\n\n\n\nincome_vs_commute = df[(df['Category'] == \"Demographics\") | (df['Category'] == \"Commuting\")]\nincome_vs_commute = income_vs_commute[income_vs_commute['Variable'].isin([\"Median Household Income\", \"Commute by car/ truck/van\"])]\nincome_vs_commute = income_vs_commute[income_vs_commute['GEOID'].isin(top_100_values_df['GEOID'])]"
  },
  {
    "objectID": "viz_Zenan/viz.html#viz-7",
    "href": "viz_Zenan/viz.html#viz-7",
    "title": "Viz 5",
    "section": "Viz 7",
    "text": "Viz 7\n\npivoted_df = income_vs_commute.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\npivoted_df.plot(kind='bar', figsize=(10, 6))\n\nplt.xlabel('County name')\nplt.ylabel('Value')\nplt.title('Comparison of Commuting (Personal vehicle) vs. Median Household Income for the Counties with top 100 most Travel')\nplt.show()\n\n\n\n\n\n\n\n\n\ntop_50_values_df = filtered_df.nlargest(50, 'Value')\npopulation_vs_commute = df[(df['Category'] == \"Demographics\") | (df['Category'] == \"Commuting\")]\npopulation_vs_commute = population_vs_commute[population_vs_commute['Variable'].isin([\"Workers\", \"Commute by car/ truck/van\", \"Commute by public transportation\", \"Work at home\",\"Population\" ])]\npopulation_vs_commute = population_vs_commute[population_vs_commute['GEOID'].isin(top_50_values_df['GEOID'])]"
  },
  {
    "objectID": "viz_Zenan/viz.html#viz-8",
    "href": "viz_Zenan/viz.html#viz-8",
    "title": "Viz 5",
    "section": "Viz 8",
    "text": "Viz 8\n\npivoted_df = population_vs_commute.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\nax = pivoted_df.plot(kind='area', figsize=(12, 6), stacked=True)\ncurrent_ticks = ax.get_xticks()\ncurrent_labels = [item.get_text() for item in ax.get_xticklabels()]\nax.set_xticks(range(len(pivoted_df.index)))  \nax.set_xticklabels(pivoted_df.index, rotation='vertical', fontsize=8) \n\nplt.xlabel('County name')\nplt.ylabel('Value')\nplt.title('Comparison of 3 Commuting methods vs Population by Counties')\nplt.tight_layout()  \nplt.show()"
  },
  {
    "objectID": "viz_Zenan/viz.html#viz-9",
    "href": "viz_Zenan/viz.html#viz-9",
    "title": "Viz 5",
    "section": "Viz 9",
    "text": "Viz 9\n\nbridge = df[df['Category'] == 'Bridges']\npivoted_df = bridge.pivot_table(index='State', columns='Variable', values='Value', aggfunc='mean')\n\nax = pivoted_df.plot(kind='barh', figsize=(10, 10))\nplt.xlabel('Value')\nplt.ylabel('State')\nplt.title('Comparison of Bridge Types by State')\nplt.xticks(rotation=75)\nplt.legend(title='Bridge Type')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "RICH/eda.html",
    "href": "RICH/eda.html",
    "title": "EDA and Munging",
    "section": "",
    "text": "In this section, we will explore a few different aspects of our dataset. We will examine the different categories and values that exist within the data, as well as the distributions for various sub-categorizations. This analysis will help contextualize which attributes of the data are most useful for addressing our areas of interest.\n\n\n\n\n\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\n\n\n\n\nCode\nwith open(\"../data/data.csv\", \"r\") as f:\n    df = pd.read_csv(f)\n    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf.head()\n\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n0\nCounty\nAirports\nTotal Airports\nGrant County, Wisconsin\n2020-01-01\n55043\n55\nWisconsin\n9.0\n9.0\nTotal Airports\nairports-2020-55043\n42.867479\n-90.706205\nPOINT (-90.706205 42.867479)\n2020\n\n\n1\nCounty\nAirports\nTotal Airports\nTaylor County, Florida\n2020-01-01\n12123\n12\nFlorida\n7.0\n7.0\nTotal Airports\nairports-2020-12123\n30.047015\n-83.603520\nPOINT (-83.60352 30.047015)\n2020\n\n\n2\nCounty\nAirports\nTotal Airports\nStephens County, Texas\n2020-01-01\n48429\n48\nTexas\n2.0\n2.0\nTotal Airports\nairports-2020-48429\n32.735872\n-98.836184\nPOINT (-98.836184 32.735872)\n2020\n\n\n3\nCounty\nAirports\nOther airports\nKnox County, Maine\n2020-01-01\n23013\n23\nMaine\n7.0\n9.0\nTotal Airports\nother-airports-2020-23013\n44.155975\n-69.234045\nPOINT (-69.234045 44.155975)\n2020\n\n\n4\nCounty\nAirports\nPrimary Airports\nColfax County, New Mexico\n2020-01-01\n35007\n35\nNew Mexico\n0.0\n5.0\nTotal Airports\nprimary-airports-2020-35007\n36.606139\n-104.646840\nPOINT (-104.64684 36.606139)\n2020\n\n\n\n\n\n\n\n\n\n\n\nCategories\n\n\n\nCode\ncats = list(df[\"Category\"].unique())\n\n\n\n\nCode\ncatVars = {}\nfor cat in cats:\n    if cat not in catVars:\n        catVars[cat] = []\n    \n    for var in df[df[\"Category\"] == cat][\"Variable\"].unique():\n        catVars[cat].append(var)\n\ncatVarDf = []\nfor i in range(max(len(catVars[k]) for k in catVars)):\n    catVarDf.append([])\n    for k in catVars:\n        try:\n            catVarDf[-1].append(catVars[k][i])\n        except Exception as e:\n            catVarDf[-1].append(\" \")\ntable = tabulate(catVarDf, headers=list(catVars.keys()))\nprint(table)\n\n\nAirports                      Bridges                            Business        Commuting                         Demographics              Maritime    Person trips                              Railroad\n----------------------------  ---------------------------------  --------------  --------------------------------  ------------------------  ----------  ----------------------------------------  --------------------\nTotal Airports                Bridges, poor                      Establishments  Workers                           Population                Marinas     Trips 1-3 miles                           Rail freight miles\nOther airports                Bridges, fair                      Employees       Commute by car/ truck/van         Hispanic                  Docks       Trips less than 1 mile                    Rail passenger miles\nPrimary Airports              Total bridges                                      Work at home                      Median Household Income               Total trips\nCommercial-service Airports   Bridges, good                                      Work in-state                     Non Hispanic White Alone              Trips 10-25 miles\nCivil use and seaplane bases  Bridge area (square meters)                        Work out-of-state                                                       Trips 25-50 miles\n                              Bridge area, poor (square meters)                  Commute by public transportation                                        Trips 100-250 miles\n                              Bridge area, fair (square meters)                  Workers wo/ a vehicle                                                   Trips 3-5 miles\n                              Bridge area, good (square meters)                                                                                          Trips 5-10 miles\n                                                                                                                                                         Trips 250-500 miles\n                                                                                                                                                         Trips 50-100 miles\n                                                                                                                                                         Trips greater than or equal to 500 miles\n\n\nTALK ABOUT WHICH CATEGORIES ARE INTERESTING"
  },
  {
    "objectID": "RICH/eda.html#import",
    "href": "RICH/eda.html#import",
    "title": "EDA and Munging",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tabulate import tabulate\n\n\n\n\nCode\nwith open(\"../data/data.csv\", \"r\") as f:\n    df = pd.read_csv(f)\n    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\ndf.head()\n\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n0\nCounty\nAirports\nTotal Airports\nGrant County, Wisconsin\n2020-01-01\n55043\n55\nWisconsin\n9.0\n9.0\nTotal Airports\nairports-2020-55043\n42.867479\n-90.706205\nPOINT (-90.706205 42.867479)\n2020\n\n\n1\nCounty\nAirports\nTotal Airports\nTaylor County, Florida\n2020-01-01\n12123\n12\nFlorida\n7.0\n7.0\nTotal Airports\nairports-2020-12123\n30.047015\n-83.603520\nPOINT (-83.60352 30.047015)\n2020\n\n\n2\nCounty\nAirports\nTotal Airports\nStephens County, Texas\n2020-01-01\n48429\n48\nTexas\n2.0\n2.0\nTotal Airports\nairports-2020-48429\n32.735872\n-98.836184\nPOINT (-98.836184 32.735872)\n2020\n\n\n3\nCounty\nAirports\nOther airports\nKnox County, Maine\n2020-01-01\n23013\n23\nMaine\n7.0\n9.0\nTotal Airports\nother-airports-2020-23013\n44.155975\n-69.234045\nPOINT (-69.234045 44.155975)\n2020\n\n\n4\nCounty\nAirports\nPrimary Airports\nColfax County, New Mexico\n2020-01-01\n35007\n35\nNew Mexico\n0.0\n5.0\nTotal Airports\nprimary-airports-2020-35007\n36.606139\n-104.646840\nPOINT (-104.64684 36.606139)\n2020"
  },
  {
    "objectID": "RICH/eda.html#groupings",
    "href": "RICH/eda.html#groupings",
    "title": "EDA and Munging",
    "section": "",
    "text": "Categories\n\n\n\nCode\ncats = list(df[\"Category\"].unique())\n\n\n\n\nCode\ncatVars = {}\nfor cat in cats:\n    if cat not in catVars:\n        catVars[cat] = []\n    \n    for var in df[df[\"Category\"] == cat][\"Variable\"].unique():\n        catVars[cat].append(var)\n\ncatVarDf = []\nfor i in range(max(len(catVars[k]) for k in catVars)):\n    catVarDf.append([])\n    for k in catVars:\n        try:\n            catVarDf[-1].append(catVars[k][i])\n        except Exception as e:\n            catVarDf[-1].append(\" \")\ntable = tabulate(catVarDf, headers=list(catVars.keys()))\nprint(table)\n\n\nAirports                      Bridges                            Business        Commuting                         Demographics              Maritime    Person trips                              Railroad\n----------------------------  ---------------------------------  --------------  --------------------------------  ------------------------  ----------  ----------------------------------------  --------------------\nTotal Airports                Bridges, poor                      Establishments  Workers                           Population                Marinas     Trips 1-3 miles                           Rail freight miles\nOther airports                Bridges, fair                      Employees       Commute by car/ truck/van         Hispanic                  Docks       Trips less than 1 mile                    Rail passenger miles\nPrimary Airports              Total bridges                                      Work at home                      Median Household Income               Total trips\nCommercial-service Airports   Bridges, good                                      Work in-state                     Non Hispanic White Alone              Trips 10-25 miles\nCivil use and seaplane bases  Bridge area (square meters)                        Work out-of-state                                                       Trips 25-50 miles\n                              Bridge area, poor (square meters)                  Commute by public transportation                                        Trips 100-250 miles\n                              Bridge area, fair (square meters)                  Workers wo/ a vehicle                                                   Trips 3-5 miles\n                              Bridge area, good (square meters)                                                                                          Trips 5-10 miles\n                                                                                                                                                         Trips 250-500 miles\n                                                                                                                                                         Trips 50-100 miles\n                                                                                                                                                         Trips greater than or equal to 500 miles\n\n\nTALK ABOUT WHICH CATEGORIES ARE INTERESTING"
  },
  {
    "objectID": "RICH/eda.html#pare-down-dataset",
    "href": "RICH/eda.html#pare-down-dataset",
    "title": "EDA and Munging",
    "section": "Pare Down Dataset",
    "text": "Pare Down Dataset\n\n\nCode\ndf[\"Level\"].unique()\n\n\narray(['County'], dtype=object)\n\n\n\n1. Reduce the Amount of Data\n\n\nCode\ncleaned = df[df[\"Category\"].isin([\"Bridges\", \"Business\", \"Commuting\", \"Demographics\", \"Person trips\"])].copy()\ncleaned.drop(columns = [\"Row-ID\",\"Level\",\"Date\",\"State FIPS\",\"Denominator\",\"Denominator Description\"], inplace = True)\ncleaned.head()\n\n\n\n\n\n\n\n\n\nCategory\nVariable\nCounty\nGEOID\nState\nValue\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n16165\nBridges\nBridges, poor\nGreeley County, Nebraska\n31077\nNebraska\n10.0\n41.567444\n-98.521218\nPOINT (-98.521218 41.567444)\n2018\n\n\n16166\nBridges\nBridges, fair\nLewis County, Missouri\n29111\nMissouri\n72.0\n40.096875\n-91.722106\nPOINT (-91.722106 40.096875)\n2017\n\n\n16167\nBridges\nBridges, fair\nKnox County, Ohio\n39083\nOhio\n107.0\n40.398760\n-82.421514\nPOINT (-82.421514 40.39876)\n2018\n\n\n16168\nBridges\nTotal bridges\nHarnett County, North Carolina\n37085\nNorth Carolina\n135.0\n35.368633\n-78.869415\nPOINT (-78.869415 35.368633)\n2017\n\n\n16169\nBridges\nTotal bridges\nGem County, Idaho\n16045\nIdaho\n56.0\n43.979330\n-116.432524\nPOINT (-116.432524 43.97933)\n2017\n\n\n\n\n\n\n\n\n\n2. Add Categories to Variable Descriptors\n\n\nCode\ndef addCategory(cat,var):\n    return f\"{cat}_{var}\"\ncleaned[\"Variable\"] = cleaned.apply(lambda row: addCategory(row['Category'], row['Variable']), axis=1)\ncleaned.drop(columns = [\"Category\"], inplace = True)\ncleaned.head()\n\n\n\n\n\n\n\n\n\nVariable\nCounty\nGEOID\nState\nValue\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n16165\nBridges_Bridges, poor\nGreeley County, Nebraska\n31077\nNebraska\n10.0\n41.567444\n-98.521218\nPOINT (-98.521218 41.567444)\n2018\n\n\n16166\nBridges_Bridges, fair\nLewis County, Missouri\n29111\nMissouri\n72.0\n40.096875\n-91.722106\nPOINT (-91.722106 40.096875)\n2017\n\n\n16167\nBridges_Bridges, fair\nKnox County, Ohio\n39083\nOhio\n107.0\n40.398760\n-82.421514\nPOINT (-82.421514 40.39876)\n2018\n\n\n16168\nBridges_Total bridges\nHarnett County, North Carolina\n37085\nNorth Carolina\n135.0\n35.368633\n-78.869415\nPOINT (-78.869415 35.368633)\n2017\n\n\n16169\nBridges_Total bridges\nGem County, Idaho\n16045\nIdaho\n56.0\n43.979330\n-116.432524\nPOINT (-116.432524 43.97933)\n2017\n\n\n\n\n\n\n\n\n\n3. Remove state names from county names\n\n\nCode\ndef dropStateFromCounty(county):\n    if county != \"District of Columbia\":\n        return county.split(\",\")[0]\n    return county\n\ncleaned[\"County\"] = cleaned[\"County\"].apply(dropStateFromCounty)\ncleaned.head()\n\n\n\n\n\n\n\n\n\nVariable\nCounty\nGEOID\nState\nValue\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n16165\nBridges_Bridges, poor\nGreeley County\n31077\nNebraska\n10.0\n41.567444\n-98.521218\nPOINT (-98.521218 41.567444)\n2018\n\n\n16166\nBridges_Bridges, fair\nLewis County\n29111\nMissouri\n72.0\n40.096875\n-91.722106\nPOINT (-91.722106 40.096875)\n2017\n\n\n16167\nBridges_Bridges, fair\nKnox County\n39083\nOhio\n107.0\n40.398760\n-82.421514\nPOINT (-82.421514 40.39876)\n2018\n\n\n16168\nBridges_Total bridges\nHarnett County\n37085\nNorth Carolina\n135.0\n35.368633\n-78.869415\nPOINT (-78.869415 35.368633)\n2017\n\n\n16169\nBridges_Total bridges\nGem County\n16045\nIdaho\n56.0\n43.979330\n-116.432524\nPOINT (-116.432524 43.97933)\n2017\n\n\n\n\n\n\n\n\n\n4. Add state abbreviation and remove territories\n\n\nCode\nstate_dict = {\n    'Alabama': 'AL','Alaska': 'AK','Arizona': 'AZ','Arkansas': 'AR','California': 'CA',\n    'Colorado': 'CO','Connecticut': 'CT','Delaware': 'DE','Florida': 'FL','Georgia': 'GA',\n    'Hawaii': 'HI','Idaho': 'ID','Illinois': 'IL','Indiana': 'IN','Iowa': 'IA','Kansas': 'KS',\n    'Kentucky': 'KY','Louisiana': 'LA','Maine': 'ME','Maryland': 'MD','Massachusetts': 'MA',\n    'Michigan': 'MI','Minnesota': 'MN','Mississippi': 'MS','Missouri': 'MO','Montana': 'MT',\n    'Nebraska': 'NE','Nevada': 'NV','New Hampshire': 'NH','New Jersey': 'NJ','New Mexico': 'NM',\n    'New York': 'NY','North Carolina': 'NC','North Dakota': 'ND','Ohio': 'OH','Oklahoma': 'OK',\n    'Oregon': 'OR','Pennsylvania': 'PA','Rhode Island': 'RI','South Carolina': 'SC','South Dakota': 'SD',\n    'Tennessee': 'TN','Texas': 'TX','Utah': 'UT','Vermont': 'VT','Virginia': 'VA','Washington': 'WA',\n    'West Virginia': 'WV','Wisconsin': 'WI','Wyoming': 'WY','District of Columbia':\"DC\"\n}\ncleaned = cleaned[cleaned[\"State\"].isin(state_dict)]\ncleaned[\"StateAbbv\"] = [state_dict[s] for s in cleaned[\"State\"]]\ncleaned.head()\n\n\n\n\n\n\n\n\n\nVariable\nCounty\nGEOID\nState\nValue\nLatitude\nLongitude\nLocation\nYear\nStateAbbv\n\n\n\n\n16165\nBridges_Bridges, poor\nGreeley County\n31077\nNebraska\n10.0\n41.567444\n-98.521218\nPOINT (-98.521218 41.567444)\n2018\nNE\n\n\n16166\nBridges_Bridges, fair\nLewis County\n29111\nMissouri\n72.0\n40.096875\n-91.722106\nPOINT (-91.722106 40.096875)\n2017\nMO\n\n\n16167\nBridges_Bridges, fair\nKnox County\n39083\nOhio\n107.0\n40.398760\n-82.421514\nPOINT (-82.421514 40.39876)\n2018\nOH\n\n\n16168\nBridges_Total bridges\nHarnett County\n37085\nNorth Carolina\n135.0\n35.368633\n-78.869415\nPOINT (-78.869415 35.368633)\n2017\nNC\n\n\n16169\nBridges_Total bridges\nGem County\n16045\nIdaho\n56.0\n43.979330\n-116.432524\nPOINT (-116.432524 43.97933)\n2017\nID\n\n\n\n\n\n\n\n\n\n5. Pivot Data to have variables as columns\n\n\nCode\ncleaned = cleaned.pivot(index=[c for c in cleaned.columns if c not in [\"Variable\",\"Value\"]], columns=[\"Variable\"], values=\"Value\")\ncleaned.reset_index(inplace = True)\n# cleaned.fillna(0, inplace = True)\ncleaned.to_csv(\"../data/cleaned.csv\", index = False)\ncleaned.head()\n\n\n\n\n\n\n\n\nVariable\nCounty\nGEOID\nState\nLatitude\nLongitude\nLocation\nYear\nStateAbbv\nBridges_Bridge area (square meters)\nBridges_Bridge area, fair (square meters)\n...\nPerson trips_Trips 1-3 miles\nPerson trips_Trips 10-25 miles\nPerson trips_Trips 100-250 miles\nPerson trips_Trips 25-50 miles\nPerson trips_Trips 250-500 miles\nPerson trips_Trips 3-5 miles\nPerson trips_Trips 5-10 miles\nPerson trips_Trips 50-100 miles\nPerson trips_Trips greater than or equal to 500 miles\nPerson trips_Trips less than 1 mile\n\n\n\n\n0\nAbbeville County\n45001\nSouth Carolina\n34.222593\n-82.459165\nPOINT (-82.459165 34.222593)\n2014\nSC\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nAbbeville County\n45001\nSouth Carolina\n34.222593\n-82.459165\nPOINT (-82.459165 34.222593)\n2015\nSC\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\nAbbeville County\n45001\nSouth Carolina\n34.222593\n-82.459165\nPOINT (-82.459165 34.222593)\n2016\nSC\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\nAbbeville County\n45001\nSouth Carolina\n34.222593\n-82.459165\nPOINT (-82.459165 34.222593)\n2017\nSC\n64177.63\n22864.17\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAbbeville County\n45001\nSouth Carolina\n34.222593\n-82.459165\nPOINT (-82.459165 34.222593)\n2018\nSC\n73924.01\n34151.20\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 40 columns"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploring Commute Dynamics",
    "section": "",
    "text": "Focused on how commuting dynamics are impacted by a variety of indicators\n\nInfrastructural: bridge quality specifically (most robust / correlated)\nDemographic: income, business presence, employee type counts\n\nAdditional coniseration about how bridge quality varies across similar indicators\n\n\n\n\nWhat is the geographic distribution of travel frequency?\nIn areas with high trip counts, how does public transportation use compare to personal vehicle use?\nHow are commute numbers related to the number of businesses in a county?\nHow are commute number/trip counts related to the quality of bridges?\nHow does income correlate with commuting methods?\nHow does population/employee numbers relate to commuting methods/trip counts?\nHow does bridge quality relate to income and population?\nHow does bridge quality relate to the length of trips?\nWhat is the geographic distribution of various lengths of trips"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Exploring Commute Dynamics",
    "section": "",
    "text": "Focused on how commuting dynamics are impacted by a variety of indicators\n\nInfrastructural: bridge quality specifically (most robust / correlated)\nDemographic: income, business presence, employee type counts\n\nAdditional coniseration about how bridge quality varies across similar indicators\n\n\n\n\nWhat is the geographic distribution of travel frequency?\nIn areas with high trip counts, how does public transportation use compare to personal vehicle use?\nHow are commute numbers related to the number of businesses in a county?\nHow are commute number/trip counts related to the quality of bridges?\nHow does income correlate with commuting methods?\nHow does population/employee numbers relate to commuting methods/trip counts?\nHow does bridge quality relate to income and population?\nHow does bridge quality relate to the length of trips?\nWhat is the geographic distribution of various lengths of trips"
  },
  {
    "objectID": "PASHA/folium-county.html",
    "href": "PASHA/folium-county.html",
    "title": "Final Project",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport folium\nfrom folium.features import GeoJsonTooltip\nimport requests\n\n\n\n\nCode\n# Path to your CSV file\ncsv_file_path = '../data/data.csv'\nvariable_options = [\n    'Total bridges',\n    'Bridges, poor',\n    'Bridges, fair',\n    'Bridges, good',\n    'Bridge area (square meters)',\n    'Bridge area, poor (square meters)',\n    'Bridge area, fair (square meters)',\n    'Bridge area, good (square meters)'\n]\n\ndf = pd.read_csv(csv_file_path)\n# df.columns\n\n\n\n\nCode\n# Mapping for renaming and scaling\nname_scale_mapping = {\n    'Total bridges': {\n        'new_name': 'Total Bridges (100)',\n        'scale': 100\n    },\n    'Bridges, poor': {\n        'new_name': 'Total Poor Bridges (100)',\n        'scale': 100\n    },\n    'Bridges, fair': {\n        'new_name': 'Total Fair Bridges (100)',\n        'scale': 100\n    },\n    'Bridges, good': {\n        'new_name': 'Total Good Bridges (100)',\n        'scale': 100\n    },\n    'Bridge area (square meters)': {\n        'new_name': 'Total Bridge Area (10k m²)',\n        'scale': 10000\n    },\n    'Bridge area, poor (square meters)': {\n        'new_name': 'Total Poor Bridge Area (10k m²)',\n        'scale': 100000\n    },\n    'Bridge area, fair (square meters)': {\n        'new_name': 'Total Fair Bridge Area (10k m²)',\n        'scale': 100000\n    },\n    'Bridge area, good (square meters)': {\n        'new_name': 'Total Good Bridge Area (10k m²)',\n        'scale': 100000\n    },\n}\n\n# Apply renaming and scaling based on the mapping\nfor original_name, props in name_scale_mapping.items():\n    updated_rows = df['Variable'] == original_name  # Capture the rows to update\n    df.loc[updated_rows, 'Variable'] = props['new_name']\n    df.loc[updated_rows, 'Value'] /= props['scale']  # Apply scaling only to the updated rows\n\nvariable_options = [props['new_name'] for props in name_scale_mapping.values()]\n\n# Define color scheme for each category\ncolor_scheme = {\n    'Total': 'Blues',\n    'Poor': 'Reds',\n    'Fair': 'Oranges',\n    'Good': 'Greens'\n}\n\n\n\n\nCode\nfolium_counties_url = \"https://raw.githubusercontent.com/python-visualization/folium/main/tests/us-counties.json\"\nus_counties = requests.get(folium_counties_url).json()\n\n# Define state FIPS codes to drop (Hawaii, Alaska, DC)\nfips_to_drop = ['02', '15', '11']  # FIPS codes for AK, HI, DC respectively\n\n# Filter out counties based on their state FIPS code\nus_counties['features'] = [\n    feature for feature in us_counties['features'] \n    if feature['id'].zfill(5)[:2] not in fips_to_drop  # Ensure IDs are 5 digits for uniform comparison\n]\n\n\n\n\nCode\n# Create a folium Map object, centered on the US, *without* a tile layer yet\nm = folium.Map(\n    [43, -100],\n    zoom_start=4,\n    tiles=None\n)\n# # Add the TileLayer to m *separately*, with control=False so that users\n# # are not able remove the layer by unchecking a checkbox\nfolium.TileLayer('CartoDB positron',name=\"Light Map\",control=False).add_to(m)\n\n\n&lt;folium.raster_layers.TileLayer at 0x132b3e250&gt;\n\n\n\n\nCode\n# Loop through each variable option to create separate choropleth layers\nfor variable in variable_options:\n    subset_df = df[df['Variable'] == variable]\n    legend_label = variable.replace('_', ' ').title()\n    if 'Poor' in variable:\n        color = color_scheme['Poor']\n    elif 'Fair' in variable:\n        color = color_scheme['Fair']\n    elif 'Good' in variable:\n        color = color_scheme['Good']\n    else:  # Default to 'Total' for any other cases, typically 'Total'\n        color = color_scheme['Total']\n\n    choro = folium.Choropleth(\n        geo_data=us_counties,\n        name=variable,\n        data=subset_df,\n        columns=['GEOID', 'Value'],  # Changed from ['State', 'Value']\n        key_on='feature.id',  # Ensure this matches your county GeoJSON\n        fill_color=color,\n        fill_opacity=0.7,\n        line_opacity=0.2,\n        legend_name=legend_label,\n        highlight=True,\n        show=(variable == 'Total Bridges (100)'),\n        overlay=False\n    ).add_to(m)\n\n    # Add tooltips to each layer\n    tooltip = GeoJsonTooltip(\n        fields=['name'],\n        aliases=['County:'],\n        localize=True,\n        sticky=False,\n        labels=True,\n        style=\"\"\"\n            background-color: #F0EFEF;\n            border: 2px solid black;\n            border-radius: 3px;\n            box-shadow: 3px;\n        \"\"\",\n        max_width=800,\n    )\n    choro.geojson.add_child(tooltip)\n\n\n\n\nCode\nfolium.LayerControl(collapsed=False).add_to(m)\n\n\n&lt;folium.map.LayerControl at 0x15d9fcd90&gt;\n\n\n\n\nCode\nm\n\n\n\n\nCode\n# the interactive chart has the ability to re-render automatically based on the provided options\n# also, the `overlay=False` option has been set to FALSE, so that only one layer can you shown as a time"
  },
  {
    "objectID": "ZENAN/commute.html",
    "href": "ZENAN/commute.html",
    "title": "Commuting Numbers",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n\n\nCode\nwith open(\"../data/data.csv\", \"r\") as f:\n    df = pd.read_csv(f)\ndf.head()\n\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n0\nCounty\nAirports\nTotal Airports\nGrant County, Wisconsin\n01/01/2020 12:00:00 AM\n55043\n55\nWisconsin\n9.0\n9.0\nTotal Airports\nairports-2020-55043\n42.867479\n-90.706205\nPOINT (-90.706205 42.867479)\n2020\n\n\n1\nCounty\nAirports\nTotal Airports\nTaylor County, Florida\n01/01/2020 12:00:00 AM\n12123\n12\nFlorida\n7.0\n7.0\nTotal Airports\nairports-2020-12123\n30.047015\n-83.603520\nPOINT (-83.60352 30.047015)\n2020\n\n\n2\nCounty\nAirports\nTotal Airports\nStephens County, Texas\n01/01/2020 12:00:00 AM\n48429\n48\nTexas\n2.0\n2.0\nTotal Airports\nairports-2020-48429\n32.735872\n-98.836184\nPOINT (-98.836184 32.735872)\n2020\n\n\n3\nCounty\nAirports\nOther airports\nKnox County, Maine\n01/01/2020 12:00:00 AM\n23013\n23\nMaine\n7.0\n9.0\nTotal Airports\nother-airports-2020-23013\n44.155975\n-69.234045\nPOINT (-69.234045 44.155975)\n2020\n\n\n4\nCounty\nAirports\nPrimary Airports\nColfax County, New Mexico\n01/01/2020 12:00:00 AM\n35007\n35\nNew Mexico\n0.0\n5.0\nTotal Airports\nprimary-airports-2020-35007\n36.606139\n-104.646840\nPOINT (-104.64684 36.606139)\n2020\n\n\n\n\n\n\n\n\n\n\n\nCode\nfiltered_df = df[(df['Category'] == 'Person trips') & (df['Variable'] == 'Total trips')]\nfiltered_df.head()\n\n\n         Level      Category     Variable                  County  \\\n338538  County  Person trips  Total trips  Adair County, Kentucky   \n338541  County  Person trips  Total trips  Cass County, Minnesota   \n338543  County  Person trips  Total trips  Dundy County, Nebraska   \n338545  County  Person trips  Total trips    Menard County, Texas   \n338547  County  Person trips  Total trips  Malheur County, Oregon   \n\n                          Date  GEOID  State FIPS      State       Value  \\\n338538  01/01/2019 12:00:00 AM  21001          21   Kentucky  26904900.0   \n338541  01/01/2020 12:00:00 AM  27021          27  Minnesota  34586025.0   \n338543  01/01/2019 12:00:00 AM  31057          31   Nebraska   2444445.0   \n338545  01/01/2020 12:00:00 AM  48327          48      Texas   2741053.0   \n338547  01/01/2019 12:00:00 AM  41045          41     Oregon  60999698.0   \n\n        Denominator Denominator Description            Row-ID   Latitude  \\\n338538   26904900.0            Person trips  trips-2019-21001  37.104170   \n338541   34586025.0            Person trips  trips-2020-27021  47.117876   \n338543    2444445.0            Person trips  trips-2019-31057  40.176201   \n338545    2741053.0            Person trips  trips-2020-48327  30.889818   \n338547   60999698.0            Person trips  trips-2019-41045  43.193414   \n\n         Longitude                       Location  Year  \n338538  -85.280620     POINT (-85.28062 37.10417)  2019  \n338541  -94.280528   POINT (-94.280528 47.117876)  2020  \n338543 -101.687947  POINT (-101.687947 40.176201)  2019  \n338545  -99.820600     POINT (-99.8206 30.889818)  2020  \n338547 -117.623150   POINT (-117.62315 43.193414)  2019  \n\n\n\n\n\n\n\nCode\naggregated_df = df.groupby('State')['Value'].sum().reset_index()\ndef abbreviate_states(states):\n    state_dict = {\n        'Alabama': 'AL', 'Alaska': 'AK', 'American Samoa': 'AS', 'Arizona': 'AZ', 'Arkansas': 'AR',\n        'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL',\n        'Georgia': 'GA', 'Guam': 'GU', 'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL',\n        'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA',\n        'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN',\n        'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n        'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n        'North Dakota': 'ND', 'Northern Mariana Islands': 'MP', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR',\n        'Pennsylvania': 'PA', 'Puerto Rico': 'PR', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',\n        'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virgin Islands': 'VI',\n        'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY',\n        'District of Columbia': 'DC'\n    }\n    abbreviated_states = [state_dict[state] if state in state_dict else state for state in states]\n\n    return abbreviated_states\n\naggregated_df['State'] = abbreviate_states(aggregated_df['State'])\n\nfig = px.choropleth(\n    aggregated_df,\n    locations='State',\n    color_continuous_scale=\"Viridis\",\n    locationmode='USA-states',\n    color='Value',\n    scope='usa',\n    title='Choropleth Map based on State Values of Travel Frequency'\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nfiltered_df = filtered_df[filtered_df['State'].isin([\"California\", \"Texas\", \"New York\", \"Florida\", \"Illinois\"])]\n\n\n\n\n\n\n\nCode\nvalues=filtered_df['Value']\nendpts = list(np.mgrid[min(values):max(values):150j])\nfig = ff.create_choropleth(fips=filtered_df['GEOID'], binning_endpoints=endpts,values=values,  legend_title='Travel Frequency by County in the top 5 States with most Aggregated Trips')\nfig.layout.template = None\nfig.update_layout(\n    legend_x = 0,\n    annotations = {'x': -0.5, 'xanchor': 'left'}\n)\nfig.show()\n\n\n                                                \n\n\n\n\nCode\ntop_100_values_df = filtered_df.nlargest(50, 'Value')\ndf_with_top100_travel = df[df['GEOID'].isin(top_100_values_df['GEOID'])]\ndf_with_top100_travel = df_with_top100_travel[df_with_top100_travel['Category'].isin(['Business', 'Commuting'])]\ndf_with_top100_travel = df_with_top100_travel[(df_with_top100_travel['Variable'] == 'Establishments') | (df_with_top100_travel['Variable'] == \"Commute by car/ truck/van\")]\n\n\n\n\nCode\npivoted_df = df_with_top100_travel.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\n\n\n\n\n\n\n\nCode\nreset_df = pivoted_df.reset_index().melt(id_vars='County', var_name='Variable', value_name='Value')\nfig = px.bar(\n    reset_df,\n    x='County',\n    y='Value',\n    color='Variable',  \n    barmode='group',\n    title='Comparison of Commuting (Personal vehicle) vs. Business (Establishments) for the Counties with top 100 most Travel',\n    labels={'Value': 'Value', 'County': 'County name'}\n)\n\nfig.update_layout(\n    xaxis_title='County name',\n    yaxis_title='Value',\n    legend_title='Variable',\n    xaxis={'categoryorder':'total ascending'}  \n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nincome_vs_commute = df[(df['Category'] == \"Demographics\") | (df['Category'] == \"Commuting\")]\nincome_vs_commute = income_vs_commute[income_vs_commute['Variable'].isin([\"Median Household Income\", \"Commute by car/ truck/van\"])]\nincome_vs_commute = income_vs_commute[income_vs_commute['GEOID'].isin(top_100_values_df['GEOID'])]\n\n\n\n\n\n\n\nCode\npivoted_df = income_vs_commute.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\npivoted_df.plot(kind='bar', figsize=(10, 6))\n\nplt.xlabel('County name')\nplt.ylabel('Value')\nplt.title('Comparison of Commuting (Personal vehicle) vs. Median Household Income for the Counties with top 100 most Travel')\nplt.show()"
  },
  {
    "objectID": "ZENAN/commute.html#get-all-rows-that-fall-into-the-category-of-person-trips-and-the-subcategory-of-total-trips",
    "href": "ZENAN/commute.html#get-all-rows-that-fall-into-the-category-of-person-trips-and-the-subcategory-of-total-trips",
    "title": "Commuting Numbers",
    "section": "",
    "text": "Code\nfiltered_df = df[(df['Category'] == 'Person trips') & (df['Variable'] == 'Total trips')]\nfiltered_df.head()\n\n\n         Level      Category     Variable                  County  \\\n338538  County  Person trips  Total trips  Adair County, Kentucky   \n338541  County  Person trips  Total trips  Cass County, Minnesota   \n338543  County  Person trips  Total trips  Dundy County, Nebraska   \n338545  County  Person trips  Total trips    Menard County, Texas   \n338547  County  Person trips  Total trips  Malheur County, Oregon   \n\n                          Date  GEOID  State FIPS      State       Value  \\\n338538  01/01/2019 12:00:00 AM  21001          21   Kentucky  26904900.0   \n338541  01/01/2020 12:00:00 AM  27021          27  Minnesota  34586025.0   \n338543  01/01/2019 12:00:00 AM  31057          31   Nebraska   2444445.0   \n338545  01/01/2020 12:00:00 AM  48327          48      Texas   2741053.0   \n338547  01/01/2019 12:00:00 AM  41045          41     Oregon  60999698.0   \n\n        Denominator Denominator Description            Row-ID   Latitude  \\\n338538   26904900.0            Person trips  trips-2019-21001  37.104170   \n338541   34586025.0            Person trips  trips-2020-27021  47.117876   \n338543    2444445.0            Person trips  trips-2019-31057  40.176201   \n338545    2741053.0            Person trips  trips-2020-48327  30.889818   \n338547   60999698.0            Person trips  trips-2019-41045  43.193414   \n\n         Longitude                       Location  Year  \n338538  -85.280620     POINT (-85.28062 37.10417)  2019  \n338541  -94.280528   POINT (-94.280528 47.117876)  2020  \n338543 -101.687947  POINT (-101.687947 40.176201)  2019  \n338545  -99.820600     POINT (-99.8206 30.889818)  2020  \n338547 -117.623150   POINT (-117.62315 43.193414)  2019"
  },
  {
    "objectID": "ZENAN/commute.html#plot-the-choropleth-of-travel-frequency-based-on-summed-values-by-state",
    "href": "ZENAN/commute.html#plot-the-choropleth-of-travel-frequency-based-on-summed-values-by-state",
    "title": "Commuting Numbers",
    "section": "",
    "text": "Code\naggregated_df = df.groupby('State')['Value'].sum().reset_index()\ndef abbreviate_states(states):\n    state_dict = {\n        'Alabama': 'AL', 'Alaska': 'AK', 'American Samoa': 'AS', 'Arizona': 'AZ', 'Arkansas': 'AR',\n        'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL',\n        'Georgia': 'GA', 'Guam': 'GU', 'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL',\n        'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA',\n        'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN',\n        'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV',\n        'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC',\n        'North Dakota': 'ND', 'Northern Mariana Islands': 'MP', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR',\n        'Pennsylvania': 'PA', 'Puerto Rico': 'PR', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',\n        'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virgin Islands': 'VI',\n        'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY',\n        'District of Columbia': 'DC'\n    }\n    abbreviated_states = [state_dict[state] if state in state_dict else state for state in states]\n\n    return abbreviated_states\n\naggregated_df['State'] = abbreviate_states(aggregated_df['State'])\n\nfig = px.choropleth(\n    aggregated_df,\n    locations='State',\n    color_continuous_scale=\"Viridis\",\n    locationmode='USA-states',\n    color='Value',\n    scope='usa',\n    title='Choropleth Map based on State Values of Travel Frequency'\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nfiltered_df = filtered_df[filtered_df['State'].isin([\"California\", \"Texas\", \"New York\", \"Florida\", \"Illinois\"])]"
  },
  {
    "objectID": "ZENAN/commute.html#filter-the-rows-featuring-the-states-with-the-top-5-travel-frequency-and-then-plot-a-choropleth-for-those-5-states-on-county-level",
    "href": "ZENAN/commute.html#filter-the-rows-featuring-the-states-with-the-top-5-travel-frequency-and-then-plot-a-choropleth-for-those-5-states-on-county-level",
    "title": "Commuting Numbers",
    "section": "",
    "text": "Code\nvalues=filtered_df['Value']\nendpts = list(np.mgrid[min(values):max(values):150j])\nfig = ff.create_choropleth(fips=filtered_df['GEOID'], binning_endpoints=endpts,values=values,  legend_title='Travel Frequency by County in the top 5 States with most Aggregated Trips')\nfig.layout.template = None\nfig.update_layout(\n    legend_x = 0,\n    annotations = {'x': -0.5, 'xanchor': 'left'}\n)\nfig.show()\n\n\n                                                \n\n\n\n\nCode\ntop_100_values_df = filtered_df.nlargest(50, 'Value')\ndf_with_top100_travel = df[df['GEOID'].isin(top_100_values_df['GEOID'])]\ndf_with_top100_travel = df_with_top100_travel[df_with_top100_travel['Category'].isin(['Business', 'Commuting'])]\ndf_with_top100_travel = df_with_top100_travel[(df_with_top100_travel['Variable'] == 'Establishments') | (df_with_top100_travel['Variable'] == \"Commute by car/ truck/van\")]\n\n\n\n\nCode\npivoted_df = df_with_top100_travel.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')"
  },
  {
    "objectID": "ZENAN/commute.html#select-the-counties-with-the-top-50-travel-frequencies-rank-counties-in-ascending-order-based-on-commuting-frequency-using-private-vehicles-with-establishments-plotted-on-the-graph-as-well",
    "href": "ZENAN/commute.html#select-the-counties-with-the-top-50-travel-frequencies-rank-counties-in-ascending-order-based-on-commuting-frequency-using-private-vehicles-with-establishments-plotted-on-the-graph-as-well",
    "title": "Commuting Numbers",
    "section": "",
    "text": "Code\nreset_df = pivoted_df.reset_index().melt(id_vars='County', var_name='Variable', value_name='Value')\nfig = px.bar(\n    reset_df,\n    x='County',\n    y='Value',\n    color='Variable',  \n    barmode='group',\n    title='Comparison of Commuting (Personal vehicle) vs. Business (Establishments) for the Counties with top 100 most Travel',\n    labels={'Value': 'Value', 'County': 'County name'}\n)\n\nfig.update_layout(\n    xaxis_title='County name',\n    yaxis_title='Value',\n    legend_title='Variable',\n    xaxis={'categoryorder':'total ascending'}  \n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nincome_vs_commute = df[(df['Category'] == \"Demographics\") | (df['Category'] == \"Commuting\")]\nincome_vs_commute = income_vs_commute[income_vs_commute['Variable'].isin([\"Median Household Income\", \"Commute by car/ truck/van\"])]\nincome_vs_commute = income_vs_commute[income_vs_commute['GEOID'].isin(top_100_values_df['GEOID'])]"
  },
  {
    "objectID": "ZENAN/commute.html#histogram-of-commuting-using-personal-vehicles-and-median-household-income-for-the-selected-counties",
    "href": "ZENAN/commute.html#histogram-of-commuting-using-personal-vehicles-and-median-household-income-for-the-selected-counties",
    "title": "Commuting Numbers",
    "section": "",
    "text": "Code\npivoted_df = income_vs_commute.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\npivoted_df.plot(kind='bar', figsize=(10, 6))\n\nplt.xlabel('County name')\nplt.ylabel('Value')\nplt.title('Comparison of Commuting (Personal vehicle) vs. Median Household Income for the Counties with top 100 most Travel')\nplt.show()"
  },
  {
    "objectID": "ZENAN/bridge.html",
    "href": "ZENAN/bridge.html",
    "title": "Bridge Quality",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nimport warnings\nwarnings.filterwarnings('ignore')\nCode\nwith open(\"../data/data.csv\", \"r\") as f:\n    df = pd.read_csv(f)\ndf.head()\n\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n0\nCounty\nAirports\nTotal Airports\nGrant County, Wisconsin\n01/01/2020 12:00:00 AM\n55043\n55\nWisconsin\n9.0\n9.0\nTotal Airports\nairports-2020-55043\n42.867479\n-90.706205\nPOINT (-90.706205 42.867479)\n2020\n\n\n1\nCounty\nAirports\nTotal Airports\nTaylor County, Florida\n01/01/2020 12:00:00 AM\n12123\n12\nFlorida\n7.0\n7.0\nTotal Airports\nairports-2020-12123\n30.047015\n-83.603520\nPOINT (-83.60352 30.047015)\n2020\n\n\n2\nCounty\nAirports\nTotal Airports\nStephens County, Texas\n01/01/2020 12:00:00 AM\n48429\n48\nTexas\n2.0\n2.0\nTotal Airports\nairports-2020-48429\n32.735872\n-98.836184\nPOINT (-98.836184 32.735872)\n2020\n\n\n3\nCounty\nAirports\nOther airports\nKnox County, Maine\n01/01/2020 12:00:00 AM\n23013\n23\nMaine\n7.0\n9.0\nTotal Airports\nother-airports-2020-23013\n44.155975\n-69.234045\nPOINT (-69.234045 44.155975)\n2020\n\n\n4\nCounty\nAirports\nPrimary Airports\nColfax County, New Mexico\n01/01/2020 12:00:00 AM\n35007\n35\nNew Mexico\n0.0\n5.0\nTotal Airports\nprimary-airports-2020-35007\n36.606139\n-104.646840\nPOINT (-104.64684 36.606139)\n2020\nCode\nfiltered_df = df[(df['Category'] == 'Person trips') & (df['Variable'] == 'Total trips')]"
  },
  {
    "objectID": "ZENAN/bridge.html#filter-out-rows-with-two-indicators-of-our-paticular-interest",
    "href": "ZENAN/bridge.html#filter-out-rows-with-two-indicators-of-our-paticular-interest",
    "title": "Bridge Quality",
    "section": "Filter out rows with two indicators of our paticular interest",
    "text": "Filter out rows with two indicators of our paticular interest\n\n\nCode\ntop_100_values_df = filtered_df.nlargest(50, 'Value')\ndf_with_top100_travel = df[df['GEOID'].isin(top_100_values_df['GEOID'])]\ndf_with_top100_travel = df_with_top100_travel[df_with_top100_travel['Category'].isin(['Bridges', 'Commuting'])]\ndf_with_top100_travel = df_with_top100_travel[(df_with_top100_travel['Variable'] == \"Bridge area, good (square meters)\") | (df_with_top100_travel['Variable'] == \"Commute by car/ truck/van\")]\ndf_with_top100_travel.head()\n\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n18362\nCounty\nBridges\nBridge area, good (square meters)\nQueens County, New York\n01/01/2018 12:00:00 AM\n36081\n36\nNew York\n212446.29\n1250590.92\nBridge area\nbridge-area-good-2018-36081\n40.702284\n-73.820270\nPOINT (-73.82027 40.702284)\n2018\n\n\n18595\nCounty\nBridges\nBridge area, good (square meters)\nBexar County, Texas\n01/01/2018 12:00:00 AM\n48029\n48\nTexas\n1416350.03\n2883966.61\nBridge area\nbridge-area-good-2018-48029\n29.448938\n-98.520005\nPOINT (-98.520005 29.448938)\n2018\n\n\n19191\nCounty\nBridges\nBridge area, good (square meters)\nAlameda County, California\n01/01/2019 12:00:00 AM\n6001\n6\nCalifornia\n709721.03\n1569829.15\nBridge area\nbridge-area-good-2019-06001\n37.597747\n-121.905734\nPOINT (-121.905734 37.597747)\n2019\n\n\n19270\nCounty\nBridges\nBridge area, good (square meters)\nSanta Clara County, California\n01/01/2017 12:00:00 AM\n6085\n6\nCalifornia\n798394.01\n1289201.01\nBridge area\nbridge-area-good-2017-06085\n37.231785\n-121.695126\nPOINT (-121.695126 37.231785)\n2017\n\n\n19703\nCounty\nBridges\nBridge area, good (square meters)\nRiverside County, California\n01/01/2019 12:00:00 AM\n6065\n6\nCalifornia\n674038.91\n1209152.26\nBridge area\nbridge-area-good-2019-06065\n33.743663\n-115.993807\nPOINT (-115.993807 33.743663)\n2019"
  },
  {
    "objectID": "ZENAN/bridge.html#plot-an-interactive-plot-for-two-indicators-commuting-by-personal-vehicle-and-bridge-area-good-for-several-counties",
    "href": "ZENAN/bridge.html#plot-an-interactive-plot-for-two-indicators-commuting-by-personal-vehicle-and-bridge-area-good-for-several-counties",
    "title": "Bridge Quality",
    "section": "Plot an interactive plot for two indicators ‘commuting by personal vehicle’ and ‘Bridge area, good’ for several counties",
    "text": "Plot an interactive plot for two indicators ‘commuting by personal vehicle’ and ‘Bridge area, good’ for several counties\n\n\nCode\npivoted_df = df_with_top100_travel.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\nlong_df = pivoted_df.reset_index().melt(id_vars='County', var_name='Variable', value_name='Value')\nfig = px.bar(\n    long_df,\n    x='County',\n    y='Value',\n    color='Variable',\n    title='Comparison of Commuting (Personal vehicle) vs. Bridges (Bridge area, good) for the Counties with top 100 most Travel',\n    labels={'Value': 'Value', 'County': 'County name'}\n)\n\nfig.update_layout(\n    xaxis={'categoryorder':'total descending'},\n    xaxis_title='County name',\n    yaxis_title='Value',\n    legend_title='Variable',\n    barmode='group'\n)\n\nfig.update_xaxes(tickangle=-45)\n\nfig.show()"
  },
  {
    "objectID": "ZENAN/bridge.html#filter-out-rows-featuring-5-states-of-our-paticular-interest-georgia-has-the-greatest-percent-of-good-bridge-while-utah-has-the-lowest-percent-of-poor-bridge",
    "href": "ZENAN/bridge.html#filter-out-rows-featuring-5-states-of-our-paticular-interest-georgia-has-the-greatest-percent-of-good-bridge-while-utah-has-the-lowest-percent-of-poor-bridge",
    "title": "Bridge Quality",
    "section": "Filter out rows featuring 5 states of our paticular interest: Georgia has the greatest percent of good bridge, while Utah has the lowest percent of poor bridge",
    "text": "Filter out rows featuring 5 states of our paticular interest: Georgia has the greatest percent of good bridge, while Utah has the lowest percent of poor bridge\n\n\nCode\nbridge = df[df['Category'] == 'Bridges']\nbridge = bridge[bridge['State'].isin([\"Georgia\", \"Utah\", \"Maryland\", \"Virginia\", \"District of Columbia\"])]\npivoted_df = bridge.pivot_table(index='State', columns='Variable', values='Value', aggfunc='mean')\npivoted_df.head()\n\n\n\n\n\n\n\n\nVariable\nBridge area (square meters)\nBridge area, fair (square meters)\nBridge area, good (square meters)\nBridge area, poor (square meters)\nBridges, fair\nBridges, good\nBridges, poor\nTotal bridges\n\n\nState\n\n\n\n\n\n\n\n\n\n\n\n\nDistrict of Columbia\n568966.237500\n451956.677500\n77175.882500\n39833.677500\n172.250000\n63.250000\n8.500000\n244.000000\n\n\nGeorgia\n63370.239827\n28856.889104\n33167.458349\n1345.892374\n45.405660\n45.474843\n2.902516\n93.783019\n\n\nMaryland\n223776.438854\n152238.142187\n64092.300208\n7445.996458\n138.697917\n73.760417\n11.541667\n224.000000\n\n\nUtah\n66849.585086\n35619.783362\n30640.537672\n589.264052\n51.681034\n51.439655\n2.370690\n105.491379\n\n\nVirginia\n76852.521530\n47371.914187\n26458.663920\n3021.943423\n65.301527\n36.080153\n4.959924\n106.341603"
  },
  {
    "objectID": "ZENAN/bridge.html#plot-the-indicators-with-relatively-large-values-for-bridge-for-each-state",
    "href": "ZENAN/bridge.html#plot-the-indicators-with-relatively-large-values-for-bridge-for-each-state",
    "title": "Bridge Quality",
    "section": "Plot the indicators with relatively large values for bridge for each state",
    "text": "Plot the indicators with relatively large values for bridge for each state\n\n\nCode\nstate_colors = {\n    'Georgia': 'blue',\n    'Utah': 'green',\n    'Maryland': 'red',\n    'Virginia': 'purple',\n    'District of Columbia': 'orange'\n}\n\nfig = go.Figure()\n\nfor state, color in state_colors.items():\n    fig.add_trace(go.Bar(\n        name=state,\n        x=pivoted_df.columns[0:4],\n        y=pivoted_df.loc[state],\n        visible=False,  \n        marker_color=color  \n    ))\n\nfig.data[0].visible = True\n\ndropdown_buttons = [\n    {'label': state,\n     'method': 'update',\n     'args': [{\n         'visible': [state == s for s in pivoted_df.index]\n     },\n         {'title': f'Bridge Types in {state}'}\n     ]}\n    for state in pivoted_df.index\n]\n\nfig.update_layout(\n    updatemenus=[{\n        'buttons': dropdown_buttons,\n        'direction': 'down',\n        'pad': {\"r\": 10, \"t\": 10},\n        'showactive': True,\n        'x': 0.1,\n        'xanchor': 'left',\n        'y': 1.1,\n        'yanchor': 'top'\n    }],\n    title_text='Comparison of Bridge Types by Selected States',\n    barmode='group'\n)\n\nfig.update_layout(title=f'Bridge Types in District of Columbia ')\nfig.update_xaxes(title_text='Bridge Type')\nfig.update_yaxes(title_text='Average Value')\nfig.show()"
  },
  {
    "objectID": "ZENAN/bridge.html#plot-the-remaining-indicators-for-bridge-for-each-state",
    "href": "ZENAN/bridge.html#plot-the-remaining-indicators-for-bridge-for-each-state",
    "title": "Bridge Quality",
    "section": "Plot the remaining indicators for bridge for each state",
    "text": "Plot the remaining indicators for bridge for each state\n\n\nCode\nstate_colors = {\n    'Georgia': 'blue',\n    'Utah': 'green',\n    'Maryland': 'red',\n    'Virginia': 'purple',\n    'District of Columbia': 'orange'\n}\n\nfig = go.Figure()\n\nfor state, color in state_colors.items():\n    fig.add_trace(go.Bar(\n        name=state,\n        x=pivoted_df.columns[4:8],\n        y=pivoted_df.loc[state],\n        visible=False,  \n        marker_color=color  \n    ))\n\nfig.data[0].visible = True\n\ndropdown_buttons = [\n    {'label': state,\n     'method': 'update',\n     'args': [{\n         'visible': [state == s for s in pivoted_df.index]\n     },\n         {'title': f'Bridge Types in {state}'}\n     ]}\n    for state in pivoted_df.index\n]\n\nfig.update_layout(\n    updatemenus=[{\n        'buttons': dropdown_buttons,\n        'direction': 'down',\n        'pad': {\"r\": 10, \"t\": 10},\n        'showactive': True,\n        'x': 0.1,\n        'xanchor': 'left',\n        'y': 1.1,\n        'yanchor': 'top'\n    }],\n    title_text='Comparison of Bridge Types by Selected States',\n    barmode='group'\n)\n\nfig.update_layout(title=f'Bridge Types in District of Columbia ')\nfig.update_xaxes(title_text='Bridge Type')\nfig.update_yaxes(title_text='Average Value')\nfig.show()"
  },
  {
    "objectID": "ZENAN/transportation.html",
    "href": "ZENAN/transportation.html",
    "title": "Transporation Methods",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport warnings\nwarnings.filterwarnings('ignore')\nCode\nwith open(\"../data/data.csv\", \"r\") as f:\n    df = pd.read_csv(f)\ndf.head()\n\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n0\nCounty\nAirports\nTotal Airports\nGrant County, Wisconsin\n01/01/2020 12:00:00 AM\n55043\n55\nWisconsin\n9.0\n9.0\nTotal Airports\nairports-2020-55043\n42.867479\n-90.706205\nPOINT (-90.706205 42.867479)\n2020\n\n\n1\nCounty\nAirports\nTotal Airports\nTaylor County, Florida\n01/01/2020 12:00:00 AM\n12123\n12\nFlorida\n7.0\n7.0\nTotal Airports\nairports-2020-12123\n30.047015\n-83.603520\nPOINT (-83.60352 30.047015)\n2020\n\n\n2\nCounty\nAirports\nTotal Airports\nStephens County, Texas\n01/01/2020 12:00:00 AM\n48429\n48\nTexas\n2.0\n2.0\nTotal Airports\nairports-2020-48429\n32.735872\n-98.836184\nPOINT (-98.836184 32.735872)\n2020\n\n\n3\nCounty\nAirports\nOther airports\nKnox County, Maine\n01/01/2020 12:00:00 AM\n23013\n23\nMaine\n7.0\n9.0\nTotal Airports\nother-airports-2020-23013\n44.155975\n-69.234045\nPOINT (-69.234045 44.155975)\n2020\n\n\n4\nCounty\nAirports\nPrimary Airports\nColfax County, New Mexico\n01/01/2020 12:00:00 AM\n35007\n35\nNew Mexico\n0.0\n5.0\nTotal Airports\nprimary-airports-2020-35007\n36.606139\n-104.646840\nPOINT (-104.64684 36.606139)\n2020\nCode\nfiltered_df = df[(df['Category'] == 'Person trips') & (df['Variable'] == 'Total trips')]"
  },
  {
    "objectID": "ZENAN/transportation.html#filter-out-rows-featuring-states-with-the-top-5-travel-frequencies",
    "href": "ZENAN/transportation.html#filter-out-rows-featuring-states-with-the-top-5-travel-frequencies",
    "title": "Transporation Methods",
    "section": "Filter out rows featuring states with the top 5 travel frequencies",
    "text": "Filter out rows featuring states with the top 5 travel frequencies\n\n\nCode\nfiltered_df = filtered_df[filtered_df['State'].isin([\"California\", \"Texas\", \"New York\", \"Florida\", \"Illinois\"])]\nfiltered_df.head()\n\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n338545\nCounty\nPerson trips\nTotal trips\nMenard County, Texas\n01/01/2020 12:00:00 AM\n48327\n48\nTexas\n2741053.0\n2741053.0\nPerson trips\ntrips-2020-48327\n30.889818\n-99.820600\nPOINT (-99.8206 30.889818)\n2020\n\n\n338552\nCounty\nPerson trips\nTotal trips\nClay County, Texas\n01/01/2019 12:00:00 AM\n48077\n48\nTexas\n11658497.0\n11658497.0\nPerson trips\ntrips-2019-48077\n33.785508\n-98.208514\nPOINT (-98.208514 33.785508)\n2019\n\n\n338553\nCounty\nPerson trips\nTotal trips\nStark County, Illinois\n01/01/2019 12:00:00 AM\n17175\n17\nIllinois\n8028854.0\n8028854.0\nPerson trips\ntrips-2019-17175\n41.093339\n-89.797473\nPOINT (-89.797473 41.093339)\n2019\n\n\n338562\nCounty\nPerson trips\nTotal trips\nKnox County, Texas\n01/01/2020 12:00:00 AM\n48275\n48\nTexas\n3832334.0\n3832334.0\nPerson trips\ntrips-2020-48275\n33.606093\n-99.741427\nPOINT (-99.741427 33.606093)\n2020\n\n\n338567\nCounty\nPerson trips\nTotal trips\nBriscoe County, Texas\n01/01/2020 12:00:00 AM\n48045\n48\nTexas\n2258298.0\n2258298.0\nPerson trips\ntrips-2020-48045\n34.530275\n-101.208553\nPOINT (-101.208553 34.530275)\n2020"
  },
  {
    "objectID": "ZENAN/transportation.html#filter-out-rows-based-on-5-selected-methods-of-commuting",
    "href": "ZENAN/transportation.html#filter-out-rows-based-on-5-selected-methods-of-commuting",
    "title": "Transporation Methods",
    "section": "Filter out rows based on 5 selected methods of commuting",
    "text": "Filter out rows based on 5 selected methods of commuting\n\n\nCode\ntop_50_values_df = filtered_df.nlargest(50, 'Value')\npopulation_vs_commute = df[(df['Category'] == \"Demographics\") | (df['Category'] == \"Commuting\")]\npopulation_vs_commute = population_vs_commute[population_vs_commute['Variable'].isin([\"Workers\", \"Commute by car/ truck/van\", \"Commute by public transportation\", \"Work at home\",\"Population\" ])]\npopulation_vs_commute = population_vs_commute[population_vs_commute['GEOID'].isin(top_50_values_df['GEOID'])]\npopulation_vs_commute.head()\n\n\n\n\n\n\n\n\n\nLevel\nCategory\nVariable\nCounty\nDate\nGEOID\nState FIPS\nState\nValue\nDenominator\nDenominator Description\nRow-ID\nLatitude\nLongitude\nLocation\nYear\n\n\n\n\n151162\nCounty\nCommuting\nWork at home\nOrange County, Florida\n01/01/2016 12:00:00 AM\n12095\n12\nFlorida\n31026.0\n611025.0\nWorkers 16 years & older\nworkers-home-2016-12095\n28.479872\n-81.260753\nPOINT (-81.260753 28.479872)\n2016\n\n\n151281\nCounty\nCommuting\nCommute by public transportation\nFresno County, California\n01/01/2016 12:00:00 AM\n6019\n6\nCalifornia\n4770.0\n368119.0\nWorkers 16 years & older\nworkers-transit-2016-06019\n37.113974\n-119.000122\nPOINT (-119.000122 37.113974)\n2016\n\n\n151513\nCounty\nCommuting\nCommute by public transportation\nTravis County, Texas\n01/01/2016 12:00:00 AM\n48453\n48\nTexas\n20421.0\n612192.0\nWorkers 16 years & older\nworkers-transit-2016-48453\n30.249986\n-97.771258\nPOINT (-97.771258 30.249986)\n2016\n\n\n151729\nCounty\nCommuting\nWorkers\nQueens County, New York\n01/01/2019 12:00:00 AM\n36081\n36\nNew York\n1101747.0\n1101747.0\nWorkers 16 years & older\nworkers-2019-36081\n40.702284\n-73.820270\nPOINT (-73.82027 40.702284)\n2019\n\n\n151790\nCounty\nCommuting\nCommute by car/ truck/van\nMiami-Dade County, Florida\n01/01/2016 12:00:00 AM\n12086\n12\nFlorida\n1041383.0\n1214352.0\nWorkers 16 years & older\nworkers-car-2016-12086\n25.615881\n-80.563710\nPOINT (-80.56371 25.615881)\n2016"
  },
  {
    "objectID": "ZENAN/transportation.html#plot-an-interactive-plot-for-the-counties-featureing-top-50-travel-frequencies-from-the-5-states-selected-before",
    "href": "ZENAN/transportation.html#plot-an-interactive-plot-for-the-counties-featureing-top-50-travel-frequencies-from-the-5-states-selected-before",
    "title": "Transporation Methods",
    "section": "Plot an interactive plot for the counties featureing top 50 travel frequencies from the 5 states selected before",
    "text": "Plot an interactive plot for the counties featureing top 50 travel frequencies from the 5 states selected before\n\n\nCode\npivoted_df = population_vs_commute.pivot_table(index='County', columns='Variable', values='Value', aggfunc='first')\nlong_df = pivoted_df.reset_index().melt(id_vars='County', var_name='Variable', value_name='Value')\n\nfig = px.line(\n    long_df,\n    x='County',\n    y='Value',\n    color='Variable',  \n    title='Comparison of 3 Commuting methods vs Population by Counties',\n    labels={'Value': 'Value', 'County': 'County name'}\n)\n\nfig.update_layout(\n    hovermode='x unified',  \n    xaxis={'tickangle': -90},  \n    xaxis_title='County name',\n    yaxis_title='Value'\n)\n\nfig.show()"
  },
  {
    "objectID": "PASHA/folium.html",
    "href": "PASHA/folium.html",
    "title": "Final Project",
    "section": "",
    "text": "import pandas as pd\nimport folium\nfrom folium.features import GeoJsonTooltip\nimport requests\n\n\n# Path to your CSV file\ncsv_file_path = '../data/data.csv'\nvariable_options = [\n    'Total bridges',\n    'Bridges, poor',\n    'Bridges, fair',\n    'Bridges, good',\n    'Bridge area (square meters)',\n    'Bridge area, poor (square meters)',\n    'Bridge area, fair (square meters)',\n    'Bridge area, good (square meters)'\n]\n\ndf = pd.read_csv(csv_file_path)\n\ndf = df.groupby(['State', 'Variable'])['Value'].sum().reset_index()\n\n\n# Mapping for renaming and scaling\nname_scale_mapping = {\n    'Total bridges': {\n        'new_name': 'Total Bridges (k)',\n        'scale': 1000\n    },\n    'Bridges, poor': {\n        'new_name': 'Total Poor Bridges (k)',\n        'scale': 1000\n    },\n    'Bridges, fair': {\n        'new_name': 'Total Fair Bridges (k)',\n        'scale': 1000\n    },\n    'Bridges, good': {\n        'new_name': 'Total Good Bridges (k)',\n        'scale': 1000\n    },\n    'Bridge area (square meters)': {\n        'new_name': 'Total Bridge Area (million m²)',\n        'scale': 1000000\n    },\n    'Bridge area, poor (square meters)': {\n        'new_name': 'Total Poor Bridge Area (million m²)',\n        'scale': 1000000\n    },\n    'Bridge area, fair (square meters)': {\n        'new_name': 'Total Fair Bridge Area (million m²)',\n        'scale': 1000000\n    },\n    'Bridge area, good (square meters)': {\n        'new_name': 'Total Good Bridge Area (million m²)',\n        'scale': 1000000\n    },\n}\n\n# Apply renaming and scaling based on the mapping\nfor original_name, props in name_scale_mapping.items():\n    updated_rows = df['Variable'] == original_name  # Capture the rows to update\n    df.loc[updated_rows, 'Variable'] = props['new_name']\n    df.loc[updated_rows, 'Value'] /= props['scale']  # Apply scaling only to the updated rows\n\nvariable_options = [props['new_name'] for props in name_scale_mapping.values()]\n\n# Define color scheme for each category\ncolor_scheme = {\n    'Total': 'Blues',\n    'Poor': 'Reds',\n    'Fair': 'Oranges',\n    'Good': 'Greens'\n}\n\n\nfolium_states_url = \"https://raw.githubusercontent.com/python-visualization/folium-example-data/main/us_states.json\"\nus_states = requests.get(folium_states_url).json()\n\n# Remove HI, AK, DC from the Folium GeoJSON data\nstates_to_drop = ['HI','AK','DC']\nus_states['features'] = [f for f in us_states['features'] if f['id'] not in states_to_drop]\n\n\n# Create a folium Map object, centered on the US, *without* a tile layer yet\nm = folium.Map(\n    [43, -100],\n    zoom_start=4,\n    tiles=None\n)\n# # Add the TileLayer to m *separately*, with control=False so that users\n# # are not able remove the layer by unchecking a checkbox\nfolium.TileLayer('CartoDB positron',name=\"Light Map\",control=False).add_to(m)\n\n&lt;folium.raster_layers.TileLayer at 0x14f703890&gt;\n\n\n\n# Loop through each variable option to create separate choropleth layers\nfor variable in variable_options:\n    subset_df = df[df['Variable'] == variable]\n    legend_label = variable.replace('_', ' ').title()\n    if 'Poor' in variable:\n        color = color_scheme['Poor']\n    elif 'Fair' in variable:\n        color = color_scheme['Fair']\n    elif 'Good' in variable:\n        color = color_scheme['Good']\n    else:  # Default to 'Total' for any other cases, typically 'Total'\n        color = color_scheme['Total']\n\n    choro = folium.Choropleth(\n        geo_data=us_states,\n        name=variable,\n        data=subset_df,\n        columns=['State', 'Value'],\n        key_on='feature.properties.name',\n        fill_color=color,\n        fill_opacity=0.7,\n        line_opacity=0.2,\n        legend_name=legend_label,\n        highlight=True,\n        show=(variable == 'Total Bridges (k)'),\n        overlay=False\n    ).add_to(m)\n\n    # Add tooltips to each layer\n    tooltip = GeoJsonTooltip(\n        fields=['name'],\n        aliases=['State:'],\n        localize=True,\n        sticky=False,\n        labels=True,\n        style=\"\"\"\n            background-color: #F0EFEF;\n            border: 2px solid black;\n            border-radius: 3px;\n            box-shadow: 3px;\n        \"\"\",\n        max_width=800,\n    )\n    choro.geojson.add_child(tooltip)\n\n\nfolium.LayerControl(collapsed=False).add_to(m)\n\n&lt;folium.map.LayerControl at 0x14f7e3150&gt;\n\n\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n# the interactive chart has the ability to re-render automatically based on the provided options\n# also, the `overlay=False` option has been set to FALSE, so that only one layer can you shown as a time"
  },
  {
    "objectID": "PASHA/explore.html",
    "href": "PASHA/explore.html",
    "title": "Exploring the Data",
    "section": "",
    "text": "In this section, you can explore the data on your own and discover which variables are more interesting to you. The purpose of this exploration is to allow you to investigate different counties and see if you find anything noteworthy. In subsequent pages, we will delve into more specific aspects of the data.\nThe data provided includes information on bridges in the United States, categorized by their condition (poor, fair, or good) and the total bridge area in square meters. You can visualize this data using choropleth maps, which display the data based on geographic regions, in this case, counties.\nThe choropleth maps are interactive, allowing you to zoom in and out, pan around the map, and toggle different data layers on and off. Each layer represents a specific variable, such as the total number of bridges or the total bridge area in a particular condition.\nBy exploring these maps, you can gain insights into the distribution of bridges across the country, identify regions with a higher concentration of bridges in poor or fair condition, and compare the total bridge area across different counties.\nFeel free to interact with the maps, switch between different data layers, and observe any patterns or outliers that catch your attention. This exploration will serve as a foundation for further analysis and discussion in the subsequent pages."
  },
  {
    "objectID": "PASHA/explore.html#data-preparation",
    "href": "PASHA/explore.html#data-preparation",
    "title": "Exploring the Data",
    "section": "Data Preparation",
    "text": "Data Preparation\nIn the data preparation part, we perform several key steps to prepare the data for visualization. We load the bridge data from a CSV file and define a mapping for renaming and scaling the variables. This mapping helps to provide more meaningful names and scales the values appropriately for better visualization. We apply the renaming and scaling to the data based on the mapping.\nAdditionally, we define a color scheme for each category of bridge condition (poor, fair, good) to ensure consistent color representation across the choropleth maps.\nLastly, we fetch the US county GeoJSON data from a URL and filter out specific states (Hawaii, Alaska, and Washington D.C.) to focus on the contiguous United States.\nThese data preparation steps ensure that the data is in a suitable format for creating the interactive choropleth maps in the subsequent sections.\n\n\nCode\nimport pandas as pd\nimport folium\nfrom folium.features import GeoJsonTooltip\nimport requests\n\n\n\n\nCode\n# Path to your CSV file\ncsv_file_path = '../data/data.csv'\nvariable_options = [\n    'Total bridges',\n    'Bridges, poor',\n    'Bridges, fair',\n    'Bridges, good',\n    'Bridge area (square meters)',\n    'Bridge area, poor (square meters)',\n    'Bridge area, fair (square meters)',\n    'Bridge area, good (square meters)'\n]\n\ndf = pd.read_csv(csv_file_path)\n# df.columns\n\n\n\n\nCode\n# Mapping for renaming and scaling\nname_scale_mapping = {\n    'Total bridges': {\n        'new_name': 'Total Bridges (100)',\n        'scale': 100\n    },\n    'Bridges, poor': {\n        'new_name': 'Total Poor Bridges (100)',\n        'scale': 100\n    },\n    'Bridges, fair': {\n        'new_name': 'Total Fair Bridges (100)',\n        'scale': 100\n    },\n    'Bridges, good': {\n        'new_name': 'Total Good Bridges (100)',\n        'scale': 100\n    },\n    'Bridge area (square meters)': {\n        'new_name': 'Total Bridge Area (10k m²)',\n        'scale': 10000\n    },\n    'Bridge area, poor (square meters)': {\n        'new_name': 'Total Poor Bridge Area (10k m²)',\n        'scale': 100000\n    },\n    'Bridge area, fair (square meters)': {\n        'new_name': 'Total Fair Bridge Area (10k m²)',\n        'scale': 100000\n    },\n    'Bridge area, good (square meters)': {\n        'new_name': 'Total Good Bridge Area (10k m²)',\n        'scale': 100000\n    },\n}\n\n# Apply renaming and scaling based on the mapping\nfor original_name, props in name_scale_mapping.items():\n    updated_rows = df['Variable'] == original_name  # Capture the rows to update\n    df.loc[updated_rows, 'Variable'] = props['new_name']\n    df.loc[updated_rows, 'Value'] /= props['scale']  # Apply scaling only to the updated rows\n\nvariable_options = [props['new_name'] for props in name_scale_mapping.values()]\n\n# Define color scheme for each category\ncolor_scheme = {\n    'Total': 'Blues',\n    'Poor': 'Reds',\n    'Fair': 'Oranges',\n    'Good': 'Greens'\n}\n\n\n\n\nCode\nfolium_counties_url = \"https://raw.githubusercontent.com/python-visualization/folium/main/tests/us-counties.json\"\nus_counties = requests.get(folium_counties_url).json()\n\n# Define state FIPS codes to drop (Hawaii, Alaska, DC)\nfips_to_drop = ['02', '15', '11']  # FIPS codes for AK, HI, DC respectively\n\n# Filter out counties based on their state FIPS code\nus_counties['features'] = [\n    feature for feature in us_counties['features']\n    if feature['id'].zfill(5)[:2] not in fips_to_drop  # Ensure IDs are 5 digits for uniform comparison\n]"
  },
  {
    "objectID": "PASHA/explore.html#data-presentation",
    "href": "PASHA/explore.html#data-presentation",
    "title": "Exploring the Data",
    "section": "Data Presentation",
    "text": "Data Presentation\n\n\nCode\n# Create a folium Map object, centered on the US, *without* a tile layer yet\nm = folium.Map(\n    [43, -100],\n    zoom_start=4,\n    tiles=None\n)\n# # Add the TileLayer to m *separately*, with control=False so that users\n# # are not able remove the layer by unchecking a checkbox\nfolium.TileLayer('CartoDB positron',name=\"Light Map\",control=False).add_to(m)\n\n\n&lt;folium.raster_layers.TileLayer at 0x16e132050&gt;\n\n\n\n\nCode\n# Loop through each variable option to create separate choropleth layers\nfor variable in variable_options:\n    subset_df = df[df['Variable'] == variable]\n    legend_label = variable.replace('_', ' ').title()\n    if 'Poor' in variable:\n        color = color_scheme['Poor']\n    elif 'Fair' in variable:\n        color = color_scheme['Fair']\n    elif 'Good' in variable:\n        color = color_scheme['Good']\n    else:  # Default to 'Total' for any other cases, typically 'Total'\n        color = color_scheme['Total']\n\n    choro = folium.Choropleth(\n        geo_data=us_counties,\n        name=variable,\n        data=subset_df,\n        columns=['GEOID', 'Value'],  # Changed from ['State', 'Value']\n        key_on='feature.id',  # Ensure this matches your county GeoJSON\n        fill_color=color,\n        fill_opacity=0.7,\n        line_opacity=0.2,\n        legend_name=legend_label,\n        highlight=True,\n        show=(variable == 'Total Bridges (100)'),\n        overlay=False\n    ).add_to(m)\n\n    # Add tooltips to each layer\n    tooltip = GeoJsonTooltip(\n        fields=['name'],\n        aliases=['County:'],\n        localize=True,\n        sticky=False,\n        labels=True,\n        style=\"\"\"\n            background-color: #F0EFEF;\n            border: 2px solid black;\n            border-radius: 3px;\n            box-shadow: 3px;\n        \"\"\",\n        max_width=800,\n    )\n    choro.geojson.add_child(tooltip)\n\n\n\n\nCode\nfolium.LayerControl(collapsed=False).add_to(m)\n\n\n&lt;folium.map.LayerControl at 0x290753750&gt;\n\n\n\n\nCode\nm\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\nCode\nm.save('.fullscreen_explore_map.html')"
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "To Be Added"
  },
  {
    "objectID": "RICH/trendOverTime.html",
    "href": "RICH/trendOverTime.html",
    "title": "Trends Over Time",
    "section": "",
    "text": "In this section, we explore how our selected variables change over time across the years for which they were collected. Specifically, we will explore changes in commuting frequency, bridge counts, and bridge quality.\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(geojsonsf)\nlibrary(leaflet)\nlibrary(tmap)\nlibrary(spData)\nlibrary(usmap)\nlibrary(dplyr)\nlibrary(ggpubr)\nlibrary(plotly)\nlibrary(ggplot2)\n\n\n\n\nCode\ndf &lt;- read.csv(\"../data/cleaned.csv\", header = T)\n# head(df, 3)\n\n\n\n\nCode\ncounties &lt;- geojson_sf(\"../data/us_counties.geojson\")\n\n\n\n\n\nWe start by examining how travel frequency has changed nationally from 2019 to 2020. We focus on these years with a specific interest in exploring how the COVID-19 pandemic impacted commuting volumes.\n\n\nCode\ntripFreq &lt;- df[, c(which(colnames(df) %in% c(\"State\",\"County\",\"Year\",\"Demographics_Population\")), grep(\"Person.trips\", names(df)))]\ntripFreq$TotalTrips &lt;- rowSums(tripFreq[, grep(\"Person.trips\", names(tripFreq))])\ntripFreq &lt;- tripFreq[, c(\"State\",\"County\",\"Year\",\"Demographics_Population\",\"TotalTrips\")]\n# head(tripFreq)\n\n\n\n\nCode\npops &lt;- tripFreq %&gt;%\n  group_by(County, State) %&gt;%\n  summarize(pops = mean(Demographics_Population, na.rm = TRUE))\ntripFreq &lt;- tripFreq %&gt;%\n  left_join(pops, by = c(\"County\" = \"County\", \"State\" = \"State\"))\n\ntripFreq &lt;- tripFreq[complete.cases(tripFreq$TotalTrips), ]\ntripFreq$TotalTrips.PerCap &lt;- tripFreq$TotalTrips / tripFreq$pops\ntripFreq &lt;- tripFreq[, c(\"State\",\"County\",\"Year\",\"TotalTrips.PerCap\")]\n# head(tripFreq)\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 4,\n  repr.plot.height = 2.5\n)\n\ntf.2019 &lt;- tripFreq %&gt;% filter(Year == (2019))\nplot.2019 &lt;- ggplot() +\n                geom_sf(data = merge(counties, tf.2019, by.x = c(\"county\",\"full\"), by.y = c(\"County\",\"State\"), all.x = TRUE),\n                        aes(fill = TotalTrips.PerCap)) +\n                scale_fill_gradient(name = \"Trips Per\\nCapita\", \n                                low = \"#66CCFF\", high = \"#336699\",na.value = \"white\",\n                                limits = c(0, 5400)) +\n                theme_void() +\n                theme(legend.position = \"right\",\n                        plot.title = element_text(hjust = 0.7, size = 14, \n                                                face = \"bold\", color = \"black\", \n                                                margin = margin(t = 10, b = -5)),  # Adjust font size, face, color, and background of the plot title\n                        plot.background = element_rect(fill = \"#aaaaaa\"),  # Set background color of the plot\n                        legend.title = element_text(size = 14),  # Adjust font size of legend title\n                        legend.text = element_text(size = 11),\n                        legend.margin = margin(t = 0, r = 20, b = 0, l = 0)) + \n                labs(title = \"Trips Per Capita, 2019\")\nplot.2019\n\n\n\n\n\n\n\n\n\n\n\nCode\ntf.2020 &lt;- tripFreq %&gt;% filter(Year == (2020))\nplot.2020 &lt;- ggplot() +\n                geom_sf(data = merge(counties, tf.2020, by.x = c(\"county\",\"full\"), by.y = c(\"County\",\"State\"), all.x = TRUE),\n                        aes(fill = TotalTrips.PerCap)) +\n                scale_fill_gradient(name = \"Trips Per\\nCapita\", \n                                low = \"#66CCFF\", high = \"#336699\",na.value = \"white\",\n                                limits = c(0, 5400)) +\n                theme_void() +\n                theme(legend.position = \"right\",\n                        plot.title = element_text(hjust = 0.7, size = 14, \n                                                face = \"bold\", color = \"black\", \n                                                margin = margin(t = 10, b = -5)),  # Adjust font size, face, color, and background of the plot title\n                        plot.background = element_rect(fill = \"#aaaaaa\"),  # Set background color of the plot\n                        legend.title = element_text(size = 14),  # Adjust font size of legend title\n                        legend.text = element_text(size = 11),\n                        legend.margin = margin(t = 0, r = 20, b = 0, l = 0)) + \n                labs(title = \"Trips Per Capita, 2020\")\nplot.2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 10,\n  repr.plot.height = 5\n)\n\ntripFreq$countyAndState &lt;- paste(tripFreq$County,\", \",tripFreq$State,sep = \"\")\ntripFreq.wide &lt;- pivot_wider(tripFreq[, c(\"countyAndState\",\"Year\",\"TotalTrips.PerCap\")], names_from = Year, values_from = TotalTrips.PerCap, id_cols = \"countyAndState\")\ntripFreq.wide$diff &lt;- tripFreq.wide$'2020' - tripFreq.wide$'2019'\n\npar(bg = \"black\")\n\nplot(0, type = \"n\", xlim = c(2018.95, 2020.05), ylim = c(-5000,6000),\n    xlab = \"\", ylab = \"\", xaxt = \"n\")\nfor (i in 1:nrow(tripFreq.wide)) {\n  lines(c(2019, 2020), c(0, tripFreq.wide$diff[i]), col = \"#1B03A3\", lwd = 0.5)  # Plot a line for each row, with a different color\n}\nlines(c(2019,2020),c(0,0), col = \"white\", lwd = 2)\n\ntitle(main = \"Change in Per Capita Trips\\nfrom 2019 to 2020, by County\", col.main = \"white\", cex.main = 1.5)\ntitle(xlab = \"Year\", col.lab = \"white\", font.lab = 2, cex.lab = 1.2)\ntitle(ylab = \"Change in Per Capita Trips\", col.lab = \"white\", font.lab = 2, cex.lab = 1.2)\n\nxlabs &lt;- c(\"2019\", \"\", \"\", \"\", \"\", \"2020\")\naxis(1, at = seq(2019, 2020, length.out = 6), labels = xlabs, col = \"white\", col.axis = \"white\")\naxis(2, col = \"white\", col.axis = \"white\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe explore infrastructural development over time as well, by exploring how bridge counts and quality have changed within recent years across the country.\n\n\nCode\nbridgeQual &lt;- df[, c(which(colnames(df) %in% c(\"State\",\"County\",\"Year\",\"Demographics_Population\")), grep(\"Bridges_Bridges..\", names(df)))]\nbridgeQual$bridgeCount &lt;- rowSums(bridgeQual[, grep(\"Bridges_Bridges..\", names(bridgeQual))])\nbridgeQual &lt;- bridgeQual %&gt;%\n  mutate(qualityScore = (Bridges_Bridges..poor + (2*Bridges_Bridges..fair) + (3*Bridges_Bridges..good))/bridgeCount)\n# head(bridgeQual)\n\n\n\n\nCode\nbridgeQual &lt;- bridgeQual[complete.cases(bridgeQual$bridgeCount), ]\n# head(bridgeQual)\n\n\n\n\nCode\nbridgeQual &lt;- bridgeQual[order(bridgeQual$State, bridgeQual$County, bridgeQual$Year), ]\nbridgeQual &lt;- bridgeQual %&gt;%\n  group_by(County, State) %&gt;%\n  fill(Demographics_Population)\n\nbridgeQual$bridgesPer1000 &lt;- (bridgeQual$bridgeCount / bridgeQual$Demographics_Population)*1000\nbridgeQual &lt;- bridgeQual[, c(\"State\",\"County\",\"Year\",\"bridgesPer1000\",\"qualityScore\")]\n# head(bridgeQual)\n\n\n\n\nCode\noptions(\n  repr.plot.width = 8,\n  repr.plot.height = 5.2\n)\n\nplotBridgePer1000 &lt;- function(year){\n        bq &lt;- bridgeQual %&gt;% filter(Year == year)\n        bq.plot &lt;- ggplot() +\n                        geom_sf(data = merge(counties, bq, by.x = c(\"county\",\"full\"), by.y = c(\"County\",\"State\"), all.x = TRUE),\n                                aes(fill = bridgesPer1000)) +\n                        scale_fill_gradient(name = \"Bridges Per\\n1000 People\", \n                                        low = \"#fbefae\", high = \"#FF6600\",na.value = \"white\",\n                                        limits = c(0, 20)) +\n                        theme_void() +\n                        theme(legend.position = \"right\",\n                                plot.title = element_text(hjust = 0.7, size = 20, \n                                                        face = \"bold\", color = \"black\", \n                                                        margin = margin(t = 10, b = -20)),\n                                plot.background = element_rect(fill = \"#aaaaaa\"),\n                                legend.title = element_text(size = 14),\n                                legend.text = element_text(size = 11),\n                                legend.margin = margin(t = 0, r = 0, b = 0, l = -40)) + \n                        labs(title = paste(\"Bridges Per 1000 People, \",year))\n        return(bq.plot)\n}\n\nplotQualityScores &lt;- function(year){\n        bq &lt;- bridgeQual %&gt;% filter(Year == year)\n        bq.plot &lt;- ggplot() +\n                        geom_sf(data = merge(counties, bq, by.x = c(\"county\",\"full\"), by.y = c(\"County\",\"State\"), all.x = TRUE),\n                                aes(fill = qualityScore)) +\n                        scale_fill_gradient2(name = \"Average Bridge Quality Score\", \n                                        mid = \"red\", high = \"green\",na.value = \"white\",\n                                        limits = c(1, 3)) +\n                        theme_void() +\n                        theme(legend.position = \"right\",\n                                plot.title = element_text(hjust = 0.7, size = 20, \n                                                        face = \"bold\", color = \"black\", \n                                                        margin = margin(t = 10, b = -20)),\n                                plot.background = element_rect(fill = \"#aaaaaa\"),\n                                legend.title = element_text(size = 14),\n                                legend.text = element_text(size = 11),\n                                legend.margin = margin(t = 0, r = 20, b = 0, l = 0)) + \n                        labs(title = paste(\"Average Bridge Quality Score, \",year))\n        return(bq.plot)\n}\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 27,\n  repr.plot.height = 5.2\n)\n\nggarrange(plotBridgePer1000(2017),\n            plotBridgePer1000(2018),\n            plotBridgePer1000(2019),\n            plotBridgePer1000(2020),\n           ncol = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 6,\n  repr.plot.height = 4\n)\n\nbridgeQual$countyAndState &lt;- paste(bridgeQual$County,\", \",bridgeQual$State,sep = \"\")\nbridgeQual.wide &lt;- pivot_wider(bridgeQual[, c(\"countyAndState\",\"Year\",\"bridgesPer1000\")], names_from = Year, values_from = bridgesPer1000, id_cols = \"countyAndState\")\n\nbridgeQual.wide$diff.2018 &lt;- bridgeQual.wide$'2018' - bridgeQual.wide$'2017'\nbridgeQual.wide$diff.2019 &lt;- bridgeQual.wide$'2019' - bridgeQual.wide$'2017'\nbridgeQual.wide$diff.2020 &lt;- bridgeQual.wide$'2020' - bridgeQual.wide$'2017'\n\npar(bg = \"black\")\n\nplot(0, type = \"n\", xlim = c(2016.5, 2020.5), ylim = c(-150,150),\n    xlab = \"\", ylab = \"\", xaxt = \"n\")\nfor (i in 1:nrow(bridgeQual.wide)) {\n  lines(c(2017, 2018), c(0, bridgeQual.wide$diff.2018[i]), col = \"darkorange\", lwd = 0.5)\n  lines(c(2018, 2019), c(bridgeQual.wide$diff.2018[i], bridgeQual.wide$diff.2019[i]), col = \"darkorange\", lwd = 0.5)\n  lines(c(2019, 2020), c(bridgeQual.wide$diff.2019[i], bridgeQual.wide$diff.2020[i]), col = \"darkorange\", lwd = 0.5)\n}\n\nlines(c(2017,2017),c(-150,150), col = \"white\", lwd = 1)\nlines(c(2018,2018),c(-150,150), col = \"white\", lwd = 1)\nlines(c(2019,2019),c(-150,150), col = \"white\", lwd = 1)\nlines(c(2020,2020),c(-150,150), col = \"white\", lwd = 1)\n\ntitle(main = \"Change in Bridges Per 1000 People\\nfrom 2017 to 2020, by County\", col.main = \"white\", cex.main = 1.2)\ntitle(xlab = \"Year\", col.lab = \"white\", font.lab = 2, cex.lab = 1.2)\ntitle(ylab = \"Change in Bridges Per 1000 People Since 2017\", col.lab = \"white\", cex.lab = 0.9)\n\nxlabs &lt;- c(\"2017\",\"2018\",\"2019\",\"2020\")\naxis(1, at = seq(2017, 2020, length.out = 4), labels = xlabs, col = \"white\", col.axis = \"white\")\naxis(2, col = \"white\", col.axis = \"white\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 27,\n  repr.plot.height = 5.2\n)\n\nggarrange(plotQualityScores(2017) + theme(legend.position = \"none\"),\n            plotQualityScores(2018) + theme(legend.position = \"none\"),\n            plotQualityScores(2019) + theme(legend.position = \"none\"),\n            plotQualityScores(2020) + theme(legend.position = \"none\"),\n           ncol = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 10,\n  repr.plot.height = 4\n)\n\nbins &lt;- c(1, 1.5, 2, 2.5, 3)\n\nqualBins &lt;- c(\"Poor\", \"Fair\", \"Good\", \"Great\")\n\nbridgeQual$scoreBin &lt;- cut(bridgeQual$qualityScore, breaks = bins, labels = qualBins)\nbarChart &lt;- table(bridgeQual$Year, bridgeQual$scoreBin)\nbarDf &lt;- as.data.frame.matrix(barChart)\ntotals &lt;- rowSums(barDf)\n\nbarDf$Year &lt;- rownames(barDf)\nrownames(barDf) &lt;- NULL\n\nfor(c in qualBins){\n    barDf[c] &lt;- barDf[c] / totals\n}\nbarDf &lt;- gather(barDf, key = \"scoreBin\", value = \"Proportion\", -Year)\n\nbarDf$scoreBin &lt;- factor(barDf$scoreBin, levels = c(\"Great\",\"Good\",\"Fair\",\"Poor\"))\n\nggplot(barDf, aes(x = Year, y = Proportion, fill = scoreBin)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Year\", y = \"Quality Score Proportion\", fill = \"Bridge\\nQuality\",\n  title = \"Proportion of Total County\\nBridge Quality Scores Over Time\") +\n  scale_fill_manual(values = c(\"green\", \"yellow\", \"orange\", \"red\")) +\n  theme_minimal() + \n  theme(\n    plot.title = element_text(hjust = 0.5, size = 24),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20),\n    legend.title = element_text(hjust = 0.5, size = 16),\n    legend.text = element_text(size = 14),\n    axis.text.x = element_text(size = 16),\n    axis.text.y = element_text(size = 16)\n  )"
  },
  {
    "objectID": "RICH/trendOverTime.html#import-packages-and-read-data",
    "href": "RICH/trendOverTime.html#import-packages-and-read-data",
    "title": "Trends Over Time",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(geojsonsf)\nlibrary(leaflet)\nlibrary(tmap)\nlibrary(spData)\nlibrary(usmap)\nlibrary(dplyr)\nlibrary(ggpubr)\nlibrary(plotly)\nlibrary(ggplot2)\n\n\n\n\nCode\ndf &lt;- read.csv(\"../data/cleaned.csv\", header = T)\n# head(df, 3)\n\n\n\n\nCode\ncounties &lt;- geojson_sf(\"../data/us_counties.geojson\")"
  },
  {
    "objectID": "RICH/trendOverTime.html#trip-frequency-over-time",
    "href": "RICH/trendOverTime.html#trip-frequency-over-time",
    "title": "Trends Over Time",
    "section": "",
    "text": "We start by examining how travel frequency has changed nationally from 2019 to 2020. We focus on these years with a specific interest in exploring how the COVID-19 pandemic impacted commuting volumes.\n\n\nCode\ntripFreq &lt;- df[, c(which(colnames(df) %in% c(\"State\",\"County\",\"Year\",\"Demographics_Population\")), grep(\"Person.trips\", names(df)))]\ntripFreq$TotalTrips &lt;- rowSums(tripFreq[, grep(\"Person.trips\", names(tripFreq))])\ntripFreq &lt;- tripFreq[, c(\"State\",\"County\",\"Year\",\"Demographics_Population\",\"TotalTrips\")]\n# head(tripFreq)\n\n\n\n\nCode\npops &lt;- tripFreq %&gt;%\n  group_by(County, State) %&gt;%\n  summarize(pops = mean(Demographics_Population, na.rm = TRUE))\ntripFreq &lt;- tripFreq %&gt;%\n  left_join(pops, by = c(\"County\" = \"County\", \"State\" = \"State\"))\n\ntripFreq &lt;- tripFreq[complete.cases(tripFreq$TotalTrips), ]\ntripFreq$TotalTrips.PerCap &lt;- tripFreq$TotalTrips / tripFreq$pops\ntripFreq &lt;- tripFreq[, c(\"State\",\"County\",\"Year\",\"TotalTrips.PerCap\")]\n# head(tripFreq)\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 4,\n  repr.plot.height = 2.5\n)\n\ntf.2019 &lt;- tripFreq %&gt;% filter(Year == (2019))\nplot.2019 &lt;- ggplot() +\n                geom_sf(data = merge(counties, tf.2019, by.x = c(\"county\",\"full\"), by.y = c(\"County\",\"State\"), all.x = TRUE),\n                        aes(fill = TotalTrips.PerCap)) +\n                scale_fill_gradient(name = \"Trips Per\\nCapita\", \n                                low = \"#66CCFF\", high = \"#336699\",na.value = \"white\",\n                                limits = c(0, 5400)) +\n                theme_void() +\n                theme(legend.position = \"right\",\n                        plot.title = element_text(hjust = 0.7, size = 14, \n                                                face = \"bold\", color = \"black\", \n                                                margin = margin(t = 10, b = -5)),  # Adjust font size, face, color, and background of the plot title\n                        plot.background = element_rect(fill = \"#aaaaaa\"),  # Set background color of the plot\n                        legend.title = element_text(size = 14),  # Adjust font size of legend title\n                        legend.text = element_text(size = 11),\n                        legend.margin = margin(t = 0, r = 20, b = 0, l = 0)) + \n                labs(title = \"Trips Per Capita, 2019\")\nplot.2019\n\n\n\n\n\n\n\n\n\n\n\nCode\ntf.2020 &lt;- tripFreq %&gt;% filter(Year == (2020))\nplot.2020 &lt;- ggplot() +\n                geom_sf(data = merge(counties, tf.2020, by.x = c(\"county\",\"full\"), by.y = c(\"County\",\"State\"), all.x = TRUE),\n                        aes(fill = TotalTrips.PerCap)) +\n                scale_fill_gradient(name = \"Trips Per\\nCapita\", \n                                low = \"#66CCFF\", high = \"#336699\",na.value = \"white\",\n                                limits = c(0, 5400)) +\n                theme_void() +\n                theme(legend.position = \"right\",\n                        plot.title = element_text(hjust = 0.7, size = 14, \n                                                face = \"bold\", color = \"black\", \n                                                margin = margin(t = 10, b = -5)),  # Adjust font size, face, color, and background of the plot title\n                        plot.background = element_rect(fill = \"#aaaaaa\"),  # Set background color of the plot\n                        legend.title = element_text(size = 14),  # Adjust font size of legend title\n                        legend.text = element_text(size = 11),\n                        legend.margin = margin(t = 0, r = 20, b = 0, l = 0)) + \n                labs(title = \"Trips Per Capita, 2020\")\nplot.2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 10,\n  repr.plot.height = 5\n)\n\ntripFreq$countyAndState &lt;- paste(tripFreq$County,\", \",tripFreq$State,sep = \"\")\ntripFreq.wide &lt;- pivot_wider(tripFreq[, c(\"countyAndState\",\"Year\",\"TotalTrips.PerCap\")], names_from = Year, values_from = TotalTrips.PerCap, id_cols = \"countyAndState\")\ntripFreq.wide$diff &lt;- tripFreq.wide$'2020' - tripFreq.wide$'2019'\n\npar(bg = \"black\")\n\nplot(0, type = \"n\", xlim = c(2018.95, 2020.05), ylim = c(-5000,6000),\n    xlab = \"\", ylab = \"\", xaxt = \"n\")\nfor (i in 1:nrow(tripFreq.wide)) {\n  lines(c(2019, 2020), c(0, tripFreq.wide$diff[i]), col = \"#1B03A3\", lwd = 0.5)  # Plot a line for each row, with a different color\n}\nlines(c(2019,2020),c(0,0), col = \"white\", lwd = 2)\n\ntitle(main = \"Change in Per Capita Trips\\nfrom 2019 to 2020, by County\", col.main = \"white\", cex.main = 1.5)\ntitle(xlab = \"Year\", col.lab = \"white\", font.lab = 2, cex.lab = 1.2)\ntitle(ylab = \"Change in Per Capita Trips\", col.lab = \"white\", font.lab = 2, cex.lab = 1.2)\n\nxlabs &lt;- c(\"2019\", \"\", \"\", \"\", \"\", \"2020\")\naxis(1, at = seq(2019, 2020, length.out = 6), labels = xlabs, col = \"white\", col.axis = \"white\")\naxis(2, col = \"white\", col.axis = \"white\")"
  },
  {
    "objectID": "RICH/trendOverTime.html#bridge-count-and-quality-over-time",
    "href": "RICH/trendOverTime.html#bridge-count-and-quality-over-time",
    "title": "Trends Over Time",
    "section": "",
    "text": "We explore infrastructural development over time as well, by exploring how bridge counts and quality have changed within recent years across the country.\n\n\nCode\nbridgeQual &lt;- df[, c(which(colnames(df) %in% c(\"State\",\"County\",\"Year\",\"Demographics_Population\")), grep(\"Bridges_Bridges..\", names(df)))]\nbridgeQual$bridgeCount &lt;- rowSums(bridgeQual[, grep(\"Bridges_Bridges..\", names(bridgeQual))])\nbridgeQual &lt;- bridgeQual %&gt;%\n  mutate(qualityScore = (Bridges_Bridges..poor + (2*Bridges_Bridges..fair) + (3*Bridges_Bridges..good))/bridgeCount)\n# head(bridgeQual)\n\n\n\n\nCode\nbridgeQual &lt;- bridgeQual[complete.cases(bridgeQual$bridgeCount), ]\n# head(bridgeQual)\n\n\n\n\nCode\nbridgeQual &lt;- bridgeQual[order(bridgeQual$State, bridgeQual$County, bridgeQual$Year), ]\nbridgeQual &lt;- bridgeQual %&gt;%\n  group_by(County, State) %&gt;%\n  fill(Demographics_Population)\n\nbridgeQual$bridgesPer1000 &lt;- (bridgeQual$bridgeCount / bridgeQual$Demographics_Population)*1000\nbridgeQual &lt;- bridgeQual[, c(\"State\",\"County\",\"Year\",\"bridgesPer1000\",\"qualityScore\")]\n# head(bridgeQual)\n\n\n\n\nCode\noptions(\n  repr.plot.width = 8,\n  repr.plot.height = 5.2\n)\n\nplotBridgePer1000 &lt;- function(year){\n        bq &lt;- bridgeQual %&gt;% filter(Year == year)\n        bq.plot &lt;- ggplot() +\n                        geom_sf(data = merge(counties, bq, by.x = c(\"county\",\"full\"), by.y = c(\"County\",\"State\"), all.x = TRUE),\n                                aes(fill = bridgesPer1000)) +\n                        scale_fill_gradient(name = \"Bridges Per\\n1000 People\", \n                                        low = \"#fbefae\", high = \"#FF6600\",na.value = \"white\",\n                                        limits = c(0, 20)) +\n                        theme_void() +\n                        theme(legend.position = \"right\",\n                                plot.title = element_text(hjust = 0.7, size = 20, \n                                                        face = \"bold\", color = \"black\", \n                                                        margin = margin(t = 10, b = -20)),\n                                plot.background = element_rect(fill = \"#aaaaaa\"),\n                                legend.title = element_text(size = 14),\n                                legend.text = element_text(size = 11),\n                                legend.margin = margin(t = 0, r = 0, b = 0, l = -40)) + \n                        labs(title = paste(\"Bridges Per 1000 People, \",year))\n        return(bq.plot)\n}\n\nplotQualityScores &lt;- function(year){\n        bq &lt;- bridgeQual %&gt;% filter(Year == year)\n        bq.plot &lt;- ggplot() +\n                        geom_sf(data = merge(counties, bq, by.x = c(\"county\",\"full\"), by.y = c(\"County\",\"State\"), all.x = TRUE),\n                                aes(fill = qualityScore)) +\n                        scale_fill_gradient2(name = \"Average Bridge Quality Score\", \n                                        mid = \"red\", high = \"green\",na.value = \"white\",\n                                        limits = c(1, 3)) +\n                        theme_void() +\n                        theme(legend.position = \"right\",\n                                plot.title = element_text(hjust = 0.7, size = 20, \n                                                        face = \"bold\", color = \"black\", \n                                                        margin = margin(t = 10, b = -20)),\n                                plot.background = element_rect(fill = \"#aaaaaa\"),\n                                legend.title = element_text(size = 14),\n                                legend.text = element_text(size = 11),\n                                legend.margin = margin(t = 0, r = 20, b = 0, l = 0)) + \n                        labs(title = paste(\"Average Bridge Quality Score, \",year))\n        return(bq.plot)\n}\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 27,\n  repr.plot.height = 5.2\n)\n\nggarrange(plotBridgePer1000(2017),\n            plotBridgePer1000(2018),\n            plotBridgePer1000(2019),\n            plotBridgePer1000(2020),\n           ncol = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 6,\n  repr.plot.height = 4\n)\n\nbridgeQual$countyAndState &lt;- paste(bridgeQual$County,\", \",bridgeQual$State,sep = \"\")\nbridgeQual.wide &lt;- pivot_wider(bridgeQual[, c(\"countyAndState\",\"Year\",\"bridgesPer1000\")], names_from = Year, values_from = bridgesPer1000, id_cols = \"countyAndState\")\n\nbridgeQual.wide$diff.2018 &lt;- bridgeQual.wide$'2018' - bridgeQual.wide$'2017'\nbridgeQual.wide$diff.2019 &lt;- bridgeQual.wide$'2019' - bridgeQual.wide$'2017'\nbridgeQual.wide$diff.2020 &lt;- bridgeQual.wide$'2020' - bridgeQual.wide$'2017'\n\npar(bg = \"black\")\n\nplot(0, type = \"n\", xlim = c(2016.5, 2020.5), ylim = c(-150,150),\n    xlab = \"\", ylab = \"\", xaxt = \"n\")\nfor (i in 1:nrow(bridgeQual.wide)) {\n  lines(c(2017, 2018), c(0, bridgeQual.wide$diff.2018[i]), col = \"darkorange\", lwd = 0.5)\n  lines(c(2018, 2019), c(bridgeQual.wide$diff.2018[i], bridgeQual.wide$diff.2019[i]), col = \"darkorange\", lwd = 0.5)\n  lines(c(2019, 2020), c(bridgeQual.wide$diff.2019[i], bridgeQual.wide$diff.2020[i]), col = \"darkorange\", lwd = 0.5)\n}\n\nlines(c(2017,2017),c(-150,150), col = \"white\", lwd = 1)\nlines(c(2018,2018),c(-150,150), col = \"white\", lwd = 1)\nlines(c(2019,2019),c(-150,150), col = \"white\", lwd = 1)\nlines(c(2020,2020),c(-150,150), col = \"white\", lwd = 1)\n\ntitle(main = \"Change in Bridges Per 1000 People\\nfrom 2017 to 2020, by County\", col.main = \"white\", cex.main = 1.2)\ntitle(xlab = \"Year\", col.lab = \"white\", font.lab = 2, cex.lab = 1.2)\ntitle(ylab = \"Change in Bridges Per 1000 People Since 2017\", col.lab = \"white\", cex.lab = 0.9)\n\nxlabs &lt;- c(\"2017\",\"2018\",\"2019\",\"2020\")\naxis(1, at = seq(2017, 2020, length.out = 4), labels = xlabs, col = \"white\", col.axis = \"white\")\naxis(2, col = \"white\", col.axis = \"white\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 27,\n  repr.plot.height = 5.2\n)\n\nggarrange(plotQualityScores(2017) + theme(legend.position = \"none\"),\n            plotQualityScores(2018) + theme(legend.position = \"none\"),\n            plotQualityScores(2019) + theme(legend.position = \"none\"),\n            plotQualityScores(2020) + theme(legend.position = \"none\"),\n           ncol = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noptions(\n  repr.plot.width = 10,\n  repr.plot.height = 4\n)\n\nbins &lt;- c(1, 1.5, 2, 2.5, 3)\n\nqualBins &lt;- c(\"Poor\", \"Fair\", \"Good\", \"Great\")\n\nbridgeQual$scoreBin &lt;- cut(bridgeQual$qualityScore, breaks = bins, labels = qualBins)\nbarChart &lt;- table(bridgeQual$Year, bridgeQual$scoreBin)\nbarDf &lt;- as.data.frame.matrix(barChart)\ntotals &lt;- rowSums(barDf)\n\nbarDf$Year &lt;- rownames(barDf)\nrownames(barDf) &lt;- NULL\n\nfor(c in qualBins){\n    barDf[c] &lt;- barDf[c] / totals\n}\nbarDf &lt;- gather(barDf, key = \"scoreBin\", value = \"Proportion\", -Year)\n\nbarDf$scoreBin &lt;- factor(barDf$scoreBin, levels = c(\"Great\",\"Good\",\"Fair\",\"Poor\"))\n\nggplot(barDf, aes(x = Year, y = Proportion, fill = scoreBin)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"Year\", y = \"Quality Score Proportion\", fill = \"Bridge\\nQuality\",\n  title = \"Proportion of Total County\\nBridge Quality Scores Over Time\") +\n  scale_fill_manual(values = c(\"green\", \"yellow\", \"orange\", \"red\")) +\n  theme_minimal() + \n  theme(\n    plot.title = element_text(hjust = 0.5, size = 24),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20),\n    legend.title = element_text(hjust = 0.5, size = 16),\n    legend.text = element_text(size = 14),\n    axis.text.x = element_text(size = 16),\n    axis.text.y = element_text(size = 16)\n  )"
  }
]